(this.webpackJsonpro_benchmark_leaderboard=this.webpackJsonpro_benchmark_leaderboard||[]).push([[0],{171:function(e,t,n){},172:function(e,t,n){},18:function(e){e.exports=JSON.parse('{"datasets":[{"task":"NER","id":"ronec-romanian-named-entity-corpus-v1-0","dataset_name":"RONEC - Romanian Named Entity Corpus v1.0","dataset_description":"<p><strong>RONEC</strong> the <strong>RO</strong>manian <strong>N</strong>amed <strong>E</strong>ntity <strong>C</strong>orpus, holds in its 1.0 version a number of 5127 sentences, annotated with 16 classes, having in total 26376 annotated entities. The target is to correctly label each token or span of tokens into its appropriate class.  </p>","dataset_info":"<h3>Input, Output and Metrics:</h3>\\n<p>Given the train &amp; validation sets, the target is to maximize the F1 score on the test set.</p>\\n<p>Please see this <a href=\\"http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/\\">resource</a> to understand more about NER evaluation.</p>\\n<p>Metric reported is the <strong>Exact Match F1 score</strong>.</p>\\n<h3>Download from:</h3>\\n<p><a href=\\"https://github.com/dumitrescustefan/ronec\\">https://github.com/dumitrescustefan/ronec</a></p>\\n<h3>Starter code:</h3>\\n<p>Not yet available, please download directly from source.</p>\\n<h3>Citation:</h3>\\n<p>If you use this dataset in a published work, please cite the following:</p>\\n<blockquote>\\n<p>Dumitrescu, Stefan Daniel, and Andrei-Marius Avram. \\"Introducing RONEC--the Romanian Named Entity Corpus.\\" arXiv preprint arXiv:1909.01247 (2019).</p>\\n</blockquote>\\n<p>or in .bibtex format:</p>\\n<blockquote>\\n<pre><code>@article{dumitrescu2019introducing,\\n  title={Introducing RONEC--the Romanian Named Entity Corpus},\\n  author={Dumitrescu, Stefan Daniel and Avram, Andrei-Marius},\\n  journal={arXiv preprint arXiv:1909.01247},\\n  year={2019}\\n}\\n</code></pre>\\n</blockquote>","dataset_link":"https://github.com/dumitrescustefan/ronec","preferred_metric":"Exact Match F1","license":"MIT","license_url":"","models":[],"metrics":[],"time_range":["Mar \'21","Apr \'21"],"data_points":[]},{"task":"Tokenization","id":"ud-romanian-rrt-treebank-v2-5-tokenization","dataset_name":"UD Romanian RRT Treebank v2.5 - Tokenization","dataset_description":"<p><strong>Universal Dependencies</strong> (<a href=\\"https://universaldependencies.org/\\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\\"https://universaldependencies.org/treebanks/ro_rrt/index.html\\">standard treebank</a> for the Romanian language.</p>\\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>","dataset_info":"<h3>Description:</h3>\\n<p><a href=\\"https://universaldependencies.org/\\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\\n<p>This page is common for the following tasks:</p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\\n<h3>Input, Output and Metrics:</h3>\\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\\nFull details on the CoNLL-U format are found <a href=\\"https://universaldependencies.org/format.html\\">here</a></p>\\n<p>To perform evaluation, please use the official script available <a href=\\"http://universaldependencies.org/conll18/evaluation.html\\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\\n<p>Per task metrics (as given by the evaluation script above):</p>\\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\\n<h3>Download from:</h3>\\n<p>Download the treebank from <a href=\\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\\">here</a>. Unzip the file.</p>\\n<h3>Starter code:</h3>\\n<p>Not yet available, please download directly from source.</p>\\n<h3>Citation:</h3>\\n<p>If you use this dataset in a published work, please cite the following:</p>\\n<blockquote>\\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\\n</blockquote>\\n<p>or, in bibtex format:</p>\\n<blockquote>\\n<p>@inproceedings{nivre-etal-2016-universal,\\n   title = \\"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\\",\\n   author = \\"Nivre, Joakim  and\\n     de Marneffe, Marie-Catherine  and\\n     Ginter, Filip  and\\n     Goldberg, Yoav  and\\n     Haji{\\\\v{c}}, Jan  and\\n     Manning, Christopher D.  and\\n     McDonald, Ryan  and\\n     Petrov, Slav  and\\n     Pyysalo, Sampo  and\\n     Silveira, Natalia  and\\n     Tsarfaty, Reut  and\\n     Zeman, Daniel\\",\\n   booktitle = \\"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}\'16)\\",\\n   month = may,\\n   year = \\"2016\\",\\n   address = \\"Portoro{\\\\v{z}}, Slovenia\\",\\n   publisher = \\"European Language Resources Association (ELRA)\\",\\n   url = \\"https://www.aclweb.org/anthology/L16-1262\\",\\n   pages = \\"1659--1666\\",\\n   abstract = \\"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\\",\\n}</p>\\n</blockquote>","dataset_link":"https://universaldependencies.org/","preferred_metric":"Tokens F1","license":"CC BY-SA 4.0","license_url":"https://creativecommons.org/licenses/by-sa/4.0/","models":[{"model":"NLP-Cube v1.0 [end-to-end]","extra_training_data":true,"paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube","submission_date":"2018-10","model_size":"","results":{"Tokens F1":99.74}},{"model":"NLP-Cube v1.1 [end-to-end]","extra_training_data":true,"paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube","submission_date":"2019-04","model_size":"","results":{"Tokens F1":99.71}}],"metrics":["Tokens F1"],"time_range":["Sep \'18","Oct \'18","Apr \'19","May \'19"],"data_points":[{"model":"NLP-Cube v1.0 [end-to-end]","submission_date":"Oct \'18","Tokens F1":99.74},{"model":"NLP-Cube v1.1 [end-to-end]","submission_date":"Apr \'19","Tokens F1":99.71}]},{"task":"Sentence Segmentation","id":"ud-romanian-rrt-treebank-v2-5-sentence-segmentation","dataset_name":"UD Romanian RRT Treebank v2.5 - Sentence Segmentation","dataset_description":"<p><strong>Universal Dependencies</strong> (<a href=\\"https://universaldependencies.org/\\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\\"https://universaldependencies.org/treebanks/ro_rrt/index.html\\">standard treebank</a> for the Romanian language.</p>\\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>","dataset_info":"<h3>Description:</h3>\\n<p><a href=\\"https://universaldependencies.org/\\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\\n<p>This page is common for the following tasks:</p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\\n<h3>Input, Output and Metrics:</h3>\\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\\nFull details on the CoNLL-U format are found <a href=\\"https://universaldependencies.org/format.html\\">here</a></p>\\n<p>To perform evaluation, please use the official script available <a href=\\"http://universaldependencies.org/conll18/evaluation.html\\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\\n<p>Per task metrics (as given by the evaluation script above):</p>\\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\\n<h3>Download from:</h3>\\n<p>Download the treebank from <a href=\\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\\">here</a>. Unzip the file.</p>\\n<h3>Starter code:</h3>\\n<p>Not yet available, please download directly from source.</p>\\n<h3>Citation:</h3>\\n<p>If you use this dataset in a published work, please cite the following:</p>\\n<blockquote>\\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\\n</blockquote>\\n<p>or, in bibtex format:</p>\\n<blockquote>\\n<p>@inproceedings{nivre-etal-2016-universal,\\n   title = \\"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\\",\\n   author = \\"Nivre, Joakim  and\\n     de Marneffe, Marie-Catherine  and\\n     Ginter, Filip  and\\n     Goldberg, Yoav  and\\n     Haji{\\\\v{c}}, Jan  and\\n     Manning, Christopher D.  and\\n     McDonald, Ryan  and\\n     Petrov, Slav  and\\n     Pyysalo, Sampo  and\\n     Silveira, Natalia  and\\n     Tsarfaty, Reut  and\\n     Zeman, Daniel\\",\\n   booktitle = \\"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}\'16)\\",\\n   month = may,\\n   year = \\"2016\\",\\n   address = \\"Portoro{\\\\v{z}}, Slovenia\\",\\n   publisher = \\"European Language Resources Association (ELRA)\\",\\n   url = \\"https://www.aclweb.org/anthology/L16-1262\\",\\n   pages = \\"1659--1666\\",\\n   abstract = \\"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\\",\\n}</p>\\n</blockquote>","dataset_link":"https://universaldependencies.org/","preferred_metric":"Sentences F1","license":"CC BY-SA 4.0","license_url":"https://creativecommons.org/licenses/by-sa/4.0/","models":[{"model":"NLP-Cube v1.0 [end-to-end]","extra_training_data":true,"paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube","submission_date":"2018-10","model_size":"","results":{"Sentences F1":95.56}},{"model":"NLP-Cube v1.1 [end-to-end]","extra_training_data":true,"paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube","submission_date":"2019-04","model_size":"","results":{"Sentences F1":95.42}}],"metrics":["Sentences F1"],"time_range":["Sep \'18","Oct \'18","Apr \'19","May \'19"],"data_points":[{"model":"NLP-Cube v1.0 [end-to-end]","submission_date":"Oct \'18","Sentences F1":95.56},{"model":"NLP-Cube v1.1 [end-to-end]","submission_date":"Apr \'19","Sentences F1":95.42}]},{"task":"Lemmatization","id":"ud-romanian-rrt-treebank-v2-5-lemmatization","dataset_name":"UD Romanian RRT Treebank v2.5 - Lemmatization","dataset_description":"<p><strong>Universal Dependencies</strong> (<a href=\\"https://universaldependencies.org/\\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\\"https://universaldependencies.org/treebanks/ro_rrt/index.html\\">standard treebank</a> for the Romanian language.</p>\\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>","dataset_info":"<h3>Description:</h3>\\n<p><a href=\\"https://universaldependencies.org/\\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\\n<p>This page is common for the following tasks:</p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\\n<h3>Input, Output and Metrics:</h3>\\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\\nFull details on the CoNLL-U format are found <a href=\\"https://universaldependencies.org/format.html\\">here</a></p>\\n<p>To perform evaluation, please use the official script available <a href=\\"http://universaldependencies.org/conll18/evaluation.html\\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\\n<p>Per task metrics (as given by the evaluation script above):</p>\\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\\n<h3>Download from:</h3>\\n<p>Download the treebank from <a href=\\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\\">here</a>. Unzip the file.</p>\\n<h3>Starter code:</h3>\\n<p>Not yet available, please download directly from source.</p>\\n<h3>Citation:</h3>\\n<p>If you use this dataset in a published work, please cite the following:</p>\\n<blockquote>\\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\\n</blockquote>\\n<p>or, in bibtex format:</p>\\n<blockquote>\\n<p>@inproceedings{nivre-etal-2016-universal,\\n   title = \\"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\\",\\n   author = \\"Nivre, Joakim  and\\n     de Marneffe, Marie-Catherine  and\\n     Ginter, Filip  and\\n     Goldberg, Yoav  and\\n     Haji{\\\\v{c}}, Jan  and\\n     Manning, Christopher D.  and\\n     McDonald, Ryan  and\\n     Petrov, Slav  and\\n     Pyysalo, Sampo  and\\n     Silveira, Natalia  and\\n     Tsarfaty, Reut  and\\n     Zeman, Daniel\\",\\n   booktitle = \\"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}\'16)\\",\\n   month = may,\\n   year = \\"2016\\",\\n   address = \\"Portoro{\\\\v{z}}, Slovenia\\",\\n   publisher = \\"European Language Resources Association (ELRA)\\",\\n   url = \\"https://www.aclweb.org/anthology/L16-1262\\",\\n   pages = \\"1659--1666\\",\\n   abstract = \\"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\\",\\n}</p>\\n</blockquote>","dataset_link":"https://universaldependencies.org/","preferred_metric":"Lemma F1","license":"CC BY-SA 4.0","license_url":"https://creativecommons.org/licenses/by-sa/4.0/","models":[{"model":"NLP-Cube v1.0 [end-to-end]","extra_training_data":true,"paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube","submission_date":"2018-10","model_size":"","results":{"Lemma F1":96.91}},{"model":"NLP-Cube v1.1 [end-to-end]","extra_training_data":true,"paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube","submission_date":"2019-04","model_size":"","results":{"Lemma F1":96.57}}],"metrics":["Lemma F1"],"time_range":["Sep \'18","Oct \'18","Apr \'19","May \'19"],"data_points":[{"model":"NLP-Cube v1.0 [end-to-end]","submission_date":"Oct \'18","Lemma F1":96.91},{"model":"NLP-Cube v1.1 [end-to-end]","submission_date":"Apr \'19","Lemma F1":96.57}]},{"task":"POS Tagging","id":"ud-romanian-rrt-treebank-v2-5-part-of-speech-tagging","dataset_name":"UD Romanian RRT Treebank v2.5 - Part of Speech Tagging","dataset_description":"<p><strong>Universal Dependencies</strong> (<a href=\\"https://universaldependencies.org/\\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\\"https://universaldependencies.org/treebanks/ro_rrt/index.html\\">standard treebank</a> for the Romanian language.</p>\\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>","dataset_info":"<h3>Description:</h3>\\n<p><a href=\\"https://universaldependencies.org/\\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\\n<p>This page is common for the following tasks:</p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\\n<h3>Input, Output and Metrics:</h3>\\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\\nFull details on the CoNLL-U format are found <a href=\\"https://universaldependencies.org/format.html\\">here</a></p>\\n<p>To perform evaluation, please use the official script available <a href=\\"http://universaldependencies.org/conll18/evaluation.html\\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\\n<p>Per task metrics (as given by the evaluation script above):</p>\\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\\n<h3>Download from:</h3>\\n<p>Download the treebank from <a href=\\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\\">here</a>. Unzip the file.</p>\\n<h3>Starter code:</h3>\\n<p>Not yet available, please download directly from source.</p>\\n<h3>Citation:</h3>\\n<p>If you use this dataset in a published work, please cite the following:</p>\\n<blockquote>\\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\\n</blockquote>\\n<p>or, in bibtex format:</p>\\n<blockquote>\\n<p>@inproceedings{nivre-etal-2016-universal,\\n   title = \\"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\\",\\n   author = \\"Nivre, Joakim  and\\n     de Marneffe, Marie-Catherine  and\\n     Ginter, Filip  and\\n     Goldberg, Yoav  and\\n     Haji{\\\\v{c}}, Jan  and\\n     Manning, Christopher D.  and\\n     McDonald, Ryan  and\\n     Petrov, Slav  and\\n     Pyysalo, Sampo  and\\n     Silveira, Natalia  and\\n     Tsarfaty, Reut  and\\n     Zeman, Daniel\\",\\n   booktitle = \\"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}\'16)\\",\\n   month = may,\\n   year = \\"2016\\",\\n   address = \\"Portoro{\\\\v{z}}, Slovenia\\",\\n   publisher = \\"European Language Resources Association (ELRA)\\",\\n   url = \\"https://www.aclweb.org/anthology/L16-1262\\",\\n   pages = \\"1659--1666\\",\\n   abstract = \\"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\\",\\n}</p>\\n</blockquote>","dataset_link":"https://universaldependencies.org/","preferred_metric":"UPOS F1","license":"CC BY-SA 4.0","license_url":"https://creativecommons.org/licenses/by-sa/4.0/","models":[{"model":"NLP-Cube v1.0 [end-to-end]","extra_training_data":true,"paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube","submission_date":"2018-10","model_size":"","results":{"UPOS F1":97.42}},{"model":"NLP-Cube v1.1 [end-to-end]","extra_training_data":true,"paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube","submission_date":"2019-04","model_size":"","results":{"UPOS F1":96.96}},{"model":"Romanian BERT Baseline (bert-base-romanian-uncased-v1)","extra_training_data":true,"paper_title":"","paper_link":"","source_link":"https://github.com/dumitrescustefan/Romanian-Transformers","submission_date":"2020-05","model_size":"","results":{"UPOS F1":98.18}}],"metrics":["UPOS F1"],"time_range":["Sep \'18","Oct \'18","Apr \'19","May \'20","Jun \'20"],"data_points":[{"model":"NLP-Cube v1.0 [end-to-end]","submission_date":"Oct \'18","UPOS F1":97.42},{"model":"NLP-Cube v1.1 [end-to-end]","submission_date":"Apr \'19","UPOS F1":96.96},{"model":"Romanian BERT Baseline (bert-base-romanian-uncased-v1)","submission_date":"May \'20","UPOS F1":98.18}]},{"task":"Dependency Parsing","id":"ud-romanian-rrt-treebank-v2-5-dependency-parsing","dataset_name":"UD Romanian RRT Treebank v2.5 - Dependency Parsing","dataset_description":"<p><strong>Universal Dependencies</strong> (<a href=\\"https://universaldependencies.org/\\">UD</a>) is a framework for consistent annotation of grammar across different human languages, and the <strong>Romanian RRT v2.5</strong> is the <a href=\\"https://universaldependencies.org/treebanks/ro_rrt/index.html\\">standard treebank</a> for the Romanian language.</p>\\n<p>The treebank contains over 200K tokens, and is composed of annotated sentences belonging to a set of different genres. On this dataset the following tasks can be performed: <strong>tokenization</strong>, <strong>sentence segmentation</strong>, <strong>lemmatization</strong>, <strong>part-of-speech tagging</strong> and <strong>dependency parsing</strong>.</p>","dataset_info":"<h3>Description:</h3>\\n<p><a href=\\"https://universaldependencies.org/\\">Universal Dependencies</a> (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. </p>\\n<p>The Romanian RRT Treebank is the standard treebank for Romanian. </p>\\n<p>This page is common for the following tasks:</p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Tokenization</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Sentence Segmentation</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Lemmatization</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>POS Tagging</strong></p>\\n<p>\u2022 UD Romanian RRT Treebank 2.5 - <strong>Dependency parsing</strong></p>\\n<h3>Input, Output and Metrics:</h3>\\n<p>There are train, dev and test files, in raw format (text) and in the CoNLL-U.\\nFull details on the CoNLL-U format are found <a href=\\"https://universaldependencies.org/format.html\\">here</a></p>\\n<p>To perform evaluation, please use the official script available <a href=\\"http://universaldependencies.org/conll18/evaluation.html\\">here</a>. It offers both prediction_file/gold_file and in-memory functions, evaluating all target metrics in one go.</p>\\n<p>Per task metrics (as given by the evaluation script above):</p>\\n<p>\u2022 <strong>Tokenization</strong>: <strong>Tokens</strong> F1 score</p>\\n<p>\u2022 <strong>Sentence Segmentation</strong>: <strong>Sentences</strong> F1 score</p>\\n<p>\u2022 <strong>Lemmatization</strong>: <strong>Lemma</strong> F1 score</p>\\n<p>\u2022 <strong>POS Tagging</strong>: <strong>UPOS</strong>, <strong>XPOS</strong> and <strong>AllTags</strong>  F1 scores</p>\\n<p>\u2022 <strong>Dependency parsing</strong>: <strong>UAS</strong> and <strong>LAS</strong> F1 scores</p>\\n<h3>Download from:</h3>\\n<p>Download the treebank from <a href=\\"https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3105/ud-treebanks-v2.5.tgz?sequence=1&amp;isAllowed=y\\">here</a>. Unzip the file.</p>\\n<h3>Starter code:</h3>\\n<p>Not yet available, please download directly from source.</p>\\n<h3>Citation:</h3>\\n<p>If you use this dataset in a published work, please cite the following:</p>\\n<blockquote>\\n<p>Joakim Nivre, Marie-Catherine de Marneffe, Filip Ginter, Yoav Goldberg, Jan Haji\u010d, Christopher D. Manning, Ryan McDonald, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Reut Tsarfaty, Daniel Zeman. 2016. Universal Dependencies v1: A Multilingual Treebank Collection. In Proceedings of LREC.</p>\\n</blockquote>\\n<p>or, in bibtex format:</p>\\n<blockquote>\\n<p>@inproceedings{nivre-etal-2016-universal,\\n   title = \\"{U}niversal {D}ependencies v1: A Multilingual Treebank Collection\\",\\n   author = \\"Nivre, Joakim  and\\n     de Marneffe, Marie-Catherine  and\\n     Ginter, Filip  and\\n     Goldberg, Yoav  and\\n     Haji{\\\\v{c}}, Jan  and\\n     Manning, Christopher D.  and\\n     McDonald, Ryan  and\\n     Petrov, Slav  and\\n     Pyysalo, Sampo  and\\n     Silveira, Natalia  and\\n     Tsarfaty, Reut  and\\n     Zeman, Daniel\\",\\n   booktitle = \\"Proceedings of the Tenth International Conference on Language Resources and Evaluation ({LREC}\'16)\\",\\n   month = may,\\n   year = \\"2016\\",\\n   address = \\"Portoro{\\\\v{z}}, Slovenia\\",\\n   publisher = \\"European Language Resources Association (ELRA)\\",\\n   url = \\"https://www.aclweb.org/anthology/L16-1262\\",\\n   pages = \\"1659--1666\\",\\n   abstract = \\"Cross-linguistically consistent annotation is necessary for sound comparative evaluation and cross-lingual learning experiments. It is also useful for multilingual system development and comparative linguistic studies. Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. In this paper, we describe v1 of the universal guidelines, the underlying design principles, and the currently available treebanks for 33 languages.\\",\\n}</p>\\n</blockquote>","dataset_link":"https://universaldependencies.org/","preferred_metric":"UAS F1","license":"CC BY-SA 4.0","license_url":"https://creativecommons.org/licenses/by-sa/4.0/","models":[{"model":"NLP-Cube v1.0 [end-to-end]","extra_training_data":true,"paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube","submission_date":"2018-10","model_size":"","results":{"UAS F1":90.38,"LAS F1":85.23}},{"model":"NLP-Cube v1.1 [end-to-end]","extra_training_data":true,"paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube","submission_date":"2019-04","model_size":"","results":{"UAS F1":90.14,"LAS F1":85.06}}],"metrics":["UAS F1","LAS F1"],"time_range":["Sep \'18","Oct \'18","Apr \'19","May \'19"],"data_points":[{"model":"NLP-Cube v1.0 [end-to-end]","submission_date":"Oct \'18","UAS F1":90.38,"LAS F1":85.23},{"model":"NLP-Cube v1.1 [end-to-end]","submission_date":"Apr \'19","UAS F1":90.14,"LAS F1":85.06}]},{"task":"Sentiment Analysis","id":"laroseda","dataset_name":"LaRoSeDa","dataset_description":"<p><strong>LaRoSeDa</strong>, the Large Romanian Sentiment Data Set, contains 15000 product reviews written in Romanian. There are 7500 positive (star ratings 4 and 5) and 7500 negative (star ratings 1 and 2) reviews. </p>","dataset_info":"<h3>Input, Output and Metrics:</h3>\\n<p>The task is to classify each review according to its star rating. Given the training set, the target is to maximize the macro-averaged F1 score on the test set.</p>\\n<p>The reported metric is the <strong>Macro-averaged F1 score</strong>.</p>\\n<h3>Download from:</h3>\\n<p><a href=\\"https://github.com/ancatache/LaRoSeDa\\">https://github.com/ancatache/LaRoSeDa</a></p>\\n<h3>Starter code:</h3>\\n<p>The following script loads the data samples into memory:</p>\\n<p><a href=\\"https://github.com/ancatache/LaRoSeDa/blob/main/load_data_set.py\\">https://github.com/ancatache/LaRoSeDa/blob/main/load_data_set.py</a></p>\\n<h3>Citation:</h3>\\n<p>If you use this dataset in a published work, please cite the following:</p>\\n<blockquote>\\n<p>Anca Maria Tache, Mihaela Gaman, Radu Tudor Ionescu. \\"Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa - A Large Romanian Sentiment Data Set\\". arXiv preprint arXiv:2101.04197, 2021. <a href=\\"https://arxiv.org/abs/2101.04197\\">Read the full paper</a>.</p>\\n</blockquote>\\n<p>or in .bibtex format:</p>\\n<blockquote>\\n<pre><code>@article{tache2021clustering,\\ntitle={Clustering Word Embeddings with Self-Organizing Maps. Application on LaRoSeDa--A Large Romanian Sentiment Data Set},\\nauthor={Tache, Anca Maria and Gaman, Mihaela and Ionescu, Radu Tudor},\\njournal={arXiv preprint arXiv:2101.04197},\\nyear={2021}\\n}\\n</code></pre>\\n</blockquote>","dataset_link":"https://github.com/ancatache/LaRoSeDa","preferred_metric":"F1","license":"CC BY-NC-SA 4.0","license_url":"https://creativecommons.org/licenses/by-nc-sa/4.0/","models":[],"metrics":[],"time_range":["Mar \'21","Apr \'21"],"data_points":[]},{"task":"Text Classification","id":"moroco","dataset_name":"MOROCO","dataset_description":"<p><strong>MOROCO</strong>, the Moldavian and Romanian Dialectal Corpus, contains Moldavian and Romanian samples of text collected from the news domain. The samples belong to one of the following six topics: culture, finance, politics, science, sports, tech. The data set is divided into three subsets: training (21719 samples), validation (5921 samples), test (5924 samples). The task is to classify each news article into its correct topic (category).</p>","dataset_info":"<h3>Input, Output and Metrics:</h3>\\n<p>The task is to classify each news article into one of the six classes. Given the training and validation sets, the target is to maximize the macro-averaged F1 score on the test set.</p>\\n<p>The reported metric is the <strong>Macro-averaged F1 score</strong>.</p>\\n<h3>Download from:</h3>\\n<p><a href=\\"https://github.com/butnaruandrei/MOROCO\\">https://github.com/butnaruandrei/MOROCO</a></p>\\n<h3>Starter code:</h3>\\n<p>The following script loads the data samples into memory:</p>\\n<p><a href=\\"https://github.com/butnaruandrei/MOROCO/blob/master/loadDataSet.py\\">https://github.com/butnaruandrei/MOROCO/blob/master/loadDataSet.py</a></p>\\n<p>With minor changes, the following script can be used for the evaluation:</p>\\n<p><a href=\\"https://github.com/butnaruandrei/MOROCO/blob/master/MOROCO/Var-Dial-MRC-2019-eval/eval.py\\">https://github.com/butnaruandrei/MOROCO/blob/master/MOROCO/Var-Dial-MRC-2019-eval/eval.py</a></p>\\n<h3>Citation:</h3>\\n<p>If you use this dataset in a published work, please cite the following:</p>\\n<blockquote>\\n<p>Andrei M. Butnaru, Radu Tudor Ionescu. \\"MOROCO: The Moldavian and Romanian Dialectal Corpus\\". In Proceedings of ACL, pp. 688\u2013698, 2019. <a href=\\"https://www.aclweb.org/anthology/P19-1068/\\">Read the full paper</a>.</p>\\n</blockquote>\\n<p>or in .bibtex format:</p>\\n<blockquote>\\n<pre><code>@inproceedings{butnaru-ionescu-2019-moroco,\\ntitle = \\"{MOROCO}: The {M}oldavian and {R}omanian Dialectal Corpus\\",\\nauthor = \\"Butnaru, Andrei and Ionescu, Radu Tudor\\",\\nbooktitle = \\"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\\",\\nmonth = jul,\\nyear = \\"2019\\",\\nurl = \\"https://www.aclweb.org/anthology/P19-1068\\",\\ndoi = \\"10.18653/v1/P19-1068\\",\\npages = \\"688--698\\"\\n}\\n</code></pre>\\n</blockquote>","dataset_link":"https://github.com/butnaruandrei/MOROCO","preferred_metric":"F1","license":"CC BY-NC-SA 4.0","license_url":"https://creativecommons.org/licenses/by-nc-sa/4.0/","models":[],"metrics":[],"time_range":["Mar \'21","Apr \'21"],"data_points":[]},{"task":"Semantic Textual Similarity","id":"ro-sts","dataset_name":"RO-STS","dataset_description":"<p>The <strong>Romanian Semantic Textual Similarity Dataset</strong> (RO-STS)[https://github.com/dumitrescustefan/RO-STS] is a high quality translation of the English <a href=\\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\\">STS</a> dataset that contains Romanian sentence pairs with their similarity scores.</p>\\n<p>The dataset consists of 8628 sentence pairs in Romanian belonging to categories such as news headlines, image captions and user forums. On this dataset the task of <strong>semantic similarity scoring</strong> can be performed.</p>","dataset_info":"<h3>Input, Output and Metrics:</h3>\\n<p>The task is to measure how similar two given sentences are.</p>\\n<p>Given the train &amp; validation sets, the target is to maximize the Pearson or Spearman correlations on the test set.</p>\\n<p>The reported metric is the <strong>Pearson or Spearman coefficient</strong>.</p>\\n<h3>Download from:</h3>\\n<p><a href=\\"https://github.com/dumitrescustefan/RO-STS/\\">https://github.com/dumitrescustefan/RO-STS/</a>\\n<a href=\\"https://github.com/dumitrescustefan/RO-STS/tree/master/dataset/text-similarity\\">Direct download of dataset</a></p>\\n<h3>Starter code:</h3>\\n<p>Not yet available, please download directly from source.</p>\\n<h3>Citation:</h3>\\n<p>If you use this dataset in a published work, please cite the following:</p>\\n<blockquote>\\n<p>Paper currently under review</p>\\n</blockquote>\\n<p>or in .bibtex format:</p>\\n<blockquote>\\n<pre><code>@article{\\n}\\n</code></pre>\\n</blockquote>","dataset_link":"https://github.com/dumitrescustefan/RO-STS","preferred_metric":"Pearson Correlation","license":"CC BY-SA 4.0","license_url":"https://creativecommons.org/licenses/by-sa/4.0/","models":[{"model":"RO-STS Baseline RNN","extra_training_data":true,"paper_title":"","paper_link":"","source_link":"https://github.com/dumitrescustefan/RO-STS","submission_date":"2020-02","model_size":"16","results":{"Pearson Correlation":0.6744,"Spearman Correlation":0.6662}},{"model":"RO-STS Baseline Romanian BERT v1 (uncased)","extra_training_data":true,"paper_title":"","paper_link":"","source_link":"https://github.com/dumitrescustefan/RO-STS","submission_date":"2020-02","model_size":"124","results":{"Pearson Correlation":0.8159,"Spearman Correlation":0.8086}},{"model":"RO-STS Baseline mBERT (uncased)","extra_training_data":true,"paper_title":"","paper_link":"","source_link":"https://github.com/dumitrescustefan/RO-STS","submission_date":"2020-02","model_size":"167","results":{"Pearson Correlation":0.769,"Spearman Correlation":0.765}}],"metrics":["Pearson Correlation","Spearman Correlation"],"time_range":["Jan \'20","Feb \'20","Mar \'20"],"data_points":[{"model":"RO-STS Baseline RNN","submission_date":"Feb \'20","Pearson Correlation":0.6744,"Spearman Correlation":0.6662},{"model":"RO-STS Baseline Romanian BERT v1 (uncased)","submission_date":"Feb \'20","Pearson Correlation":0.8159,"Spearman Correlation":0.8086},{"model":"RO-STS Baseline mBERT (uncased)","submission_date":"Feb \'20","Pearson Correlation":0.769,"Spearman Correlation":0.765}]},{"task":"Machine Translation","id":"ro-sts-parallel","dataset_name":"RO-STS-parallel","dataset_description":"<p>The <strong>Romanian Semantic Textual Similarity Parallel Dataset</strong> (RO-STS-Parallel)[https://github.com/dumitrescustefan/RO-STS] is a high quality translation of the English <a href=\\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\\">STS</a> dataset that serves as a Romanian English parallel dataset.</p>\\n<p>The dataset consists of 17256 sentence pairs in Romanian and English belonging to categories such as news headlines, image captions and user forums. On this dataset the task of <strong>machine translation</strong> can be performed.</p>","dataset_info":"<h3>Description:</h3>\\n<p>RO-STS-parallel, a parallel Romanian-English dataset is obtained by translating the English <a href=\\"https://ixa2.si.ehu.eus/stswiki/index.php/STSbenchmark\\">STS</a> dataset into Romanian. It contains 17256 sentences in Romanian and English. The data set is divided into three subsets: training (11498 sentence pairs), validation (3000 sentence pairs), test (2758 sentence pairs).</p>\\n<h3>Input, Output and Metrics:</h3>\\n<p>The task is to translate a sentence from a source to a target language.</p>\\n<p>Given the train &amp; validation sets, the target is to maximize the BLEU or ROUGE-L score on the test set.</p>\\n<p>The reported metric is the <strong>BLEU or ROUGE-L score</strong>.</p>\\n<h3>Download from:</h3>\\n<p><a href=\\"https://github.com/dumitrescustefan/RO-STS/\\">https://github.com/dumitrescustefan/RO-STS/</a>\\n<a href=\\"https://github.com/dumitrescustefan/RO-STS/tree/master/dataset/ro-en\\">Direct download of dataset</a></p>\\n<h3>Starter code:</h3>\\n<p>Not yet available, please download directly from source.</p>\\n<h3>Citation:</h3>\\n<p>If you use this dataset in a published work, please cite the following:</p>\\n<blockquote>\\n<p>Paper currently under review</p>\\n</blockquote>\\n<p>or in .bibtex format:</p>\\n<blockquote>\\n<pre><code>@article{\\n}\\n</code></pre>\\n</blockquote>","dataset_link":"https://github.com/dumitrescustefan/RO-STS","preferred_metric":"BLEU","license":"CC BY-SA 4.0","license_url":"https://creativecommons.org/licenses/by-sa/4.0/","models":[],"metrics":[],"time_range":["Mar \'21","Apr \'21"],"data_points":[]},{"task":"Machine Translation","id":"wmt16-en-ro","dataset_name":"WMT16-EN-RO","dataset_description":"<h3>Description:</h3>\\n<p>WMT16 is a Romanian-English parallel corpus containing approximately 614k of parallel sentences taken from Europarl and SETTIMES2.</p>","dataset_info":"<h3>Description:</h3>\\n<p>Workshop on Machine Translation (WMT) is a conference that builds on a series of annual workshops and conferences on \\nstatistical machine translation, going back to 2006. In the year 2016, a dataset for Romanian-English translation was proposed,\\ncontaining approximately 614k of parallel sentences taken from Europarl and SETTIMES2.</p>\\n<h3>Input, Output and Metrics:</h3>\\n<p>Given the train &amp; validation sets, the target is to maximize the BLEU score on the test set.</p>\\n<p>The reported metric is the <strong>BLEU score</strong>.</p>\\n<h3>Download from:</h3>\\n<p><a href=\\"https://www.statmt.org/wmt16/translation-task.html\\">https://www.statmt.org/wmt16/translation-task.html</a></p>\\n<h3>Starter code:</h3>\\n<p>Not yet available, please download directly from source.</p>\\n<h3>Citation:</h3>\\n<p>If you use this dataset in a published work, please cite the following:</p>\\n<blockquote>\\n<p>Bojar, Ond\u0159ej, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias Huck, Antonio Jimeno Yepes et al. \\"Findings of the 2016 conference on machine translation.\\" In Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers, pp. 131-198. 2016.</p>\\n</blockquote>\\n<p>or in .bibtex format:</p>\\n<blockquote>\\n<pre><code>@inproceedings{bojar2016findings,\\n  title={Findings of the 2016 conference on machine translation},\\n  author={Bojar, Ond{\\\\v{r}}ej and Chatterjee, Rajen and Federmann, Christian and Graham, Yvette and Haddow, Barry and Huck, Matthias and Yepes, Antonio Jimeno and Koehn, Philipp and Logacheva, Varvara and Monz, Christof and others},\\n  booktitle={Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers},\\n  pages={131--198},\\n  year={2016}\\n}\\n</code></pre>\\n</blockquote>","dataset_link":"https://www.statmt.org/wmt16/translation-task.html#download","preferred_metric":"BLEU","license":"Not specified","license_url":"","models":[],"metrics":[],"time_range":["Mar \'21","Apr \'21"],"data_points":[]},{"task":"Question Answering","id":"xquad-ro","dataset_name":"XQuAD-ro","dataset_description":"<p><strong>XQuAD</strong> (Cross-lingual Question Answering Dataset) is a benchmark dataset for evaluating cross-lingual question answering performance. The dataset consists of a subset of 240 paragraphs and 1190 question-answer pairs from the development set of SQuAD v1.1 together with their professional translations into Spanish, German, Greek, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi and <em>Romanian</em>. Consequently, the dataset is entirely parallel across all languages. The target is to evaluate QA performance on the Romanian section of the corpus, by cross-lingual transfer (e.g. zero-shot on the Romanian data after being trained on one or more languages from the corpus excluding Romanian). </p>","dataset_info":"<h3>Input, Output and Metrics:</h3>\\n<p>XQuAD is intended as an evaluation corpus for zero-shot cross-lingual transfer. Evaluation on the test data should ideally only be conducted at the very end of the experimentation in order to avoid overfitting to the data.</p>\\n<p>Please see this <a href=\\"https://github.com/deepmind/xquad\\">resource</a> to understand more about XQuAD evaluation.</p>\\n<p>Metrics reported: <strong>Macro-averaged F1 score</strong> and <strong>Exact Match</strong>.</p>\\n<h3>Download from:</h3>\\n<p><a href=\\"https://github.com/deepmind/xquad\\">https://github.com/deepmind/xquad</a></p>\\n<h3>Starter code:</h3>\\n<p>Not yet available, please download directly from source.</p>\\n<h3>Citation:</h3>\\n<p>Coming soon.</p>","dataset_link":"https://github.com/deepmind/xquad","preferred_metric":"F1","license":"CC BY-SA 4.0","license_url":"https://creativecommons.org/licenses/by-sa/4.0/","models":[{"model":"mBERT","extra_training_data":true,"paper_title":"(results available online only, Romanian evaluated by DeepMind XQuAD dataset creators)","paper_link":"https://github.com/deepmind/xquad","source_link":"","submission_date":"2020-01","model_size":"178","results":{"F1":72.7,"EM":59.9}},{"model":"XLM-R Large","extra_training_data":true,"paper_title":"(results available online only, Romanian evaluated by DeepMind XQuAD dataset creators)","paper_link":"https://github.com/deepmind/xquad","source_link":"","submission_date":"2020-01","model_size":"550","results":{"F1":83.6,"EM":69.7}}],"metrics":["F1","EM"],"time_range":["Dec \'19","Jan \'20","Feb \'20"],"data_points":[{"model":"mBERT","submission_date":"Jan \'20","F1":72.7,"EM":59.9},{"model":"XLM-R Large","submission_date":"Jan \'20","F1":83.6,"EM":69.7}]}]}')},197:function(e,t){},215:function(e,t,n){},217:function(e,t,n){},218:function(e,t,n){},219:function(e,t,n){},220:function(e,t,n){},221:function(e,t,n){},222:function(e,t,n){},227:function(e,t,n){},228:function(e,t,n){},232:function(e,t,n){},233:function(e,t,n){},234:function(e,t,n){"use strict";n.r(t);var a=n(1),i=n(2),s=n.n(i),r=n(25),o=n.n(r),l=n(62),c=n(8),d=n(89),h=n.n(d),u=n(9),p=n(10),m=n(12),g=n(11),b=n(50),f=n(90),j=(n(171),function(){function e(){Object(u.a)(this,e)}return Object(p.a)(e,[{key:"normalizeUrl",value:function(e){return e.toLowerCase()}},{key:"getCanonicalUrl",value:function(t){return this.normalizeUrl(t).replace(e.basePath,"")}},{key:"isHomeUrl",value:function(e){var t=this.getCanonicalUrl(e);return""===t||"/"===t}},{key:"buildTaskUrl",value:function(t){var n=t.id,a="".concat(e.basePath,"/task/").concat(n);return this.normalizeUrl(a)}},{key:"isTaskUrl",value:function(e){return this.getCanonicalUrl(e).startsWith("/task")}},{key:"getTaskId",value:function(e){return this.getCanonicalUrl(e).replace("/task/","")}},{key:"buildDatasetUrl",value:function(t){var n=t.id,a="".concat(e.basePath,"/dataset/").concat(n);return this.normalizeUrl(a)}},{key:"isDatasetUrl",value:function(e){var t=this.getCanonicalUrl(e);return t.startsWith("/dataset")&&!t.startsWith("/datasets")}},{key:"getDatasetId",value:function(e){return this.getCanonicalUrl(e).replace("/dataset/","")}}],[{key:"basePath",get:function(){return"/ro_benchmark_leaderboard"}},{key:"datasetsPageUrl",get:function(){return"".concat(e.basePath,"/datasets")}},{key:"taskUrlTemplate",get:function(){return"/task/:id"}},{key:"datasetUrlTemplate",get:function(){return"/dataset/:id"}},{key:"aboutPageUrl",get:function(){return"".concat(e.basePath,"/about")}},{key:"submitPageUrl",get:function(){return"".concat(e.basePath,"/submit")}},{key:"termsAndConditionsPageUrl",get:function(){return"".concat(e.basePath,"/terms-and-conditions")}},{key:"privacyStatementPageUrl",get:function(){return"".concat(e.basePath,"/privacy-statement")}}]),e}()),y=n.p+"static/media/logo-banner.75fcd774.png",v=function(e){Object(m.a)(n,e);var t=Object(g.a)(n);function n(e){var a;return Object(u.a)(this,n),(a=t.call(this,e)).urlBuilder=new j,a.state={activeArea:null},a}return Object(p.a)(n,[{key:"updateactiveArea",value:function(e){var t=this.state.activeArea;this.setState({activeArea:e!==t?e:null})}},{key:"renderDataset",value:function(e){return Object(a.jsxs)("tr",{children:[Object(a.jsx)("td",{children:e.dataset}),Object(a.jsx)("td",{children:e.submission_count})]},e.dataset)}},{key:"renderTaskSubmissions",value:function(e){if(!e.summary)return Object(a.jsx)("span",{children:"No submissions"});var t=e.summary;return Object(a.jsx)("table",{children:Object(a.jsxs)("tbody",{children:[Object(a.jsxs)("tr",{children:[Object(a.jsx)("td",{children:t.dataset_count}),Object(a.jsx)("td",{children:1===t.dataset_count?"dataset":"datasets"})]}),Object(a.jsxs)("tr",{children:[Object(a.jsx)("td",{children:t.submission_count}),Object(a.jsx)("td",{children:1===t.submission_count?"submission":"submissions"})]})]})})}},{key:"renderAreaTask",value:function(e){return Object(a.jsx)("a",{href:this.urlBuilder.buildTaskUrl(e),className:"task-tile-link",children:Object(a.jsxs)("div",{className:"task-tile",children:[Object(a.jsx)("h5",{children:e.name}),Object(a.jsx)("div",{className:"task-data",children:this.renderTaskSubmissions(e)})]},e.name)})}},{key:"renderArea",value:function(e){var t=this,n=this.state.activeArea,i=e.tasks,s=e.name,r=n===s;return Object(a.jsxs)("div",{className:"tile-wrapper",children:[Object(a.jsx)("div",{onClick:function(){return t.updateactiveArea(s)},className:"collapse-trigger",children:Object(a.jsx)("h4",{children:e.name})}),Object(a.jsx)(b.Collapse,{isOpened:r,children:Object(a.jsxs)("div",{className:"task-wrapper",children:[i.map((function(e){return t.renderAreaTask(e)})),Object(a.jsx)("div",{className:"clear"})]})})]},e.name)}},{key:"render",value:function(){var e=this,t=f.areas;if(!this.state.activeArea){var n=t[0];this.setState({activeArea:n.name})}return Object(a.jsxs)(a.Fragment,{children:[Object(a.jsxs)("div",{className:"banner",children:[Object(a.jsx)("div",{className:"logo",children:Object(a.jsx)("img",{src:y,alt:"LiRo benchmark"})}),Object(a.jsxs)("div",{className:"intro",children:[Object(a.jsxs)("p",{children:["LiRo (",Object(a.jsx)("em",{children:"Li"}),"mba ",Object(a.jsx)("em",{children:"Ro"}),"m\xe2n\u0103) provides a benchmark for Romanian language tasks."]}),Object(a.jsx)("p",{children:"The project keeps track of performance of different published models on the datasets and tasks listed below. This allows easy comparison of different models and monitoring progress on these tasks and datasets over time."})]})]}),t.map((function(t){return e.renderArea(t)}))]})}}]),n}(s.a.Component),k=n(26),O=function(){return Object(a.jsx)("svg",{version:"1.0",xmlns:"http://www.w3.org/2000/svg",width:"32",height:"32",viewBox:"0 0 602.000000 556.000000",preserveAspectRatio:"xMidYMid meet",children:Object(a.jsx)("g",{transform:"translate(0.000000,556.000000) scale(0.100000,-0.100000)",fill:"#000000",stroke:"none",children:Object(a.jsx)("path",{d:"m 2665,5025 c -288,-25 -455,-58 -675,-132 -184,-63 -397,-174 -621,-324 -47,-32 -92,-64 -100,-71 -8,-7 -32,-26 -54,-43 -60,-45 -111,-90 -205,-185 -278,-278 -448,-603 -515,-980 -20,-113 -20,-472 0,-590 13,-81 34,-184 54,-260 13,-52 71,-218 94,-270 67,-153 79,-175 220,-411 9,-17 26,-40 37,-51 11,-12 20,-25 20,-29 0,-4 6,-14 13,-21 6,-7 25,-31 41,-53 131,-178 355,-398 576,-566 47,-35 87,-67 90,-70 21,-24 280,-178 390,-231 174,-85 248,-118 260,-118 6,0 18,-4 28,-9 27,-15 107,-31 152,-31 22,0 60,10 85,21 79,37 108,95 141,289 13,74 28,153 33,175 6,22 14,58 19,80 27,111 92,257 153,341 97,133 192,175 559,246 96,19 359,88 405,107 11,5 58,20 105,35 85,28 178,60 215,77 11,4 56,22 100,40 83,32 102,40 225,96 112,51 155,73 265,132 94,50 314,186 325,200 3,3 21,18 40,32 127,95 230,250 289,436 71,223 73,565 6,818 -8,28 -21,77 -30,110 -87,330 -344,603 -780,828 -79,40 -202,97 -255,116 -19,7 -44,17 -55,22 -88,39 -415,133 -590,169 -143,30 -372,60 -575,75 -226,17 -281,17 -485,0 z m 545,-185 c 52,-5 122,-12 155,-15 33,-3 83,-10 110,-15 28,-5 82,-14 120,-20 185,-30 546,-128 660,-179 11,-5 52,-22 90,-37 120,-48 265,-123 272,-140 11,-29 -105,-292 -147,-334 -14,-14 -33,-20 -63,-20 -120,0 -202,-111 -183,-247 8,-63 50,-118 113,-148 93,-45 188,-24 256,55 42,49 52,93 42,190 l -7,69 55,108 c 30,60 62,129 72,155 31,84 32,84 169,-32 86,-73 226,-239 226,-268 0,-6 4,-12 8,-14 11,-4 72,-158 83,-208 4,-19 15,-64 23,-99 27,-105 46,-255 46,-355 0,-212 -73,-461 -168,-575 l -28,-34 -50,33 c -27,19 -58,42 -68,52 -11,10 -24,18 -29,18 -6,0 -24,11 -42,24 -17,14 -47,33 -66,44 -19,11 -62,35 -96,55 -81,46 -103,53 -103,32 0,-8 -14,-43 -30,-76 -17,-33 -28,-64 -25,-70 4,-5 25,-19 47,-30 42,-22 257,-159 296,-190 l 23,-18 -61,-41 c -177,-120 -515,-287 -790,-390 -47,-17 -94,-35 -105,-40 -78,-34 -405,-132 -535,-160 -30,-6 -71,-16 -91,-21 -20,-5 -39,-9 -42,-9 -14,0 -27,44 -42,145 l -16,108 47,46 c 53,53 84,115 84,172 0,80 -65,170 -147,204 -101,43 -232,-16 -279,-124 -33,-78 -5,-194 60,-247 17,-14 39,-32 49,-40 12,-10 17,-29 17,-66 0,-29 4,-71 9,-93 5,-22 12,-63 15,-92 l 7,-52 -58,-18 c -180,-55 -327,-187 -421,-378 -71,-144 -98,-234 -142,-475 -30,-166 -40,-204 -53,-212 -14,-10 -88,0 -101,13 -6,5 -16,9 -22,9 -7,0 -48,16 -91,35 -247,111 -465,245 -678,416 -115,94 -284,254 -274,262 2,3 36,24 74,48 101,62 169,116 263,208 75,73 87,81 121,81 68,0 100,12 146,52 61,54 76,87 77,164 1,129 -87,214 -221,214 -50,0 -66,-5 -107,-32 -83,-56 -114,-142 -91,-252 8,-38 7,-39 -65,-111 -78,-77 -201,-168 -282,-206 l -48,-24 -30,35 c -16,19 -55,71 -87,115 -207,291 -332,583 -382,891 -13,81 -8,108 18,100 10,-3 68,-13 128,-23 140,-22 610,-26 720,-5 145,28 347,77 377,93 24,13 69,10 98,-6 14,-8 52,-14 85,-14 71,-1 122,24 169,82 29,36 31,44 31,121 0,75 -3,86 -27,119 -44,57 -82,78 -148,84 -113,11 -194,-44 -225,-151 -18,-62 -23,-64 -157,-99 -203,-53 -318,-67 -540,-67 -110,0 -229,6 -298,16 -63,8 -144,19 -179,24 -35,5 -68,14 -72,22 -21,32 3,251 45,416 22,86 67,214 95,269 4,10 19,38 31,63 12,25 57,97 99,160 109,165 364,417 504,500 43,25 72,17 113,-34 50,-61 84,-142 99,-238 6,-39 28,-51 52,-27 6,6 38,13 72,16 33,3 61,6 61,7 0,1 -7,33 -16,71 -9,39 -18,82 -21,98 -3,15 -9,30 -14,33 -5,3 -9,12 -9,20 0,19 -59,109 -96,148 -20,21 -25,33 -18,44 6,8 73,48 149,88 138,72 347,148 475,172 224,43 245,45 258,29 10,-12 27,-68 39,-130 3,-15 9,-30 14,-33 5,-3 9,-14 9,-25 0,-10 4,-27 9,-37 5,-9 37,-74 70,-144 57,-120 138,-250 194,-315 14,-15 55,-63 92,-105 37,-43 71,-78 75,-78 5,0 8,-42 7,-92 -1,-77 3,-101 21,-138 39,-80 84,-122 164,-151 120,-44 245,-6 325,99 55,72 68,172 36,271 -20,64 -107,149 -171,169 -61,18 -144,15 -204,-8 l -52,-20 -34,33 c -160,153 -327,434 -393,664 -21,74 -23,73 188,73 103,-1 231,-5 283,-10 z"})})})},w=function(){return Object(a.jsx)("svg",{viewBox:"0 0 512 512",width:"16",height:"16",children:Object(a.jsx)("path",{fillRule:"evenodd",fill:"#fff",d:"M256 32C132.3 32 32 134.9 32 261.7c0 101.5 64.2 187.5 153.2 217.9a17.56 17.56 0 003.8.4c8.3 0 11.5-6.1 11.5-11.4 0-5.5-.2-19.9-.3-39.1a102.4 102.4 0 01-22.6 2.7c-43.1 0-52.9-33.5-52.9-33.5-10.2-26.5-24.9-33.6-24.9-33.6-19.5-13.7-.1-14.1 1.4-14.1h.1c22.5 2 34.3 23.8 34.3 23.8 11.2 19.6 26.2 25.1 39.6 25.1a63 63 0 0025.6-6c2-14.8 7.8-24.9 14.2-30.7-49.7-5.8-102-25.5-102-113.5 0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8a18.64 18.64 0 015-.5c8.1 0 26.4 3.1 56.6 24.1a208.21 208.21 0 01112.2 0c30.2-21 48.5-24.1 56.6-24.1a18.64 18.64 0 015 .5c12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6 0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5 0 30.7-.3 55.5-.3 63 0 5.4 3.1 11.5 11.4 11.5a19.35 19.35 0 004-.4C415.9 449.2 480 363.1 480 261.7 480 134.9 379.7 32 256 32z"})})},x=function(){return Object(a.jsx)("svg",{viewBox:"0 0 512 512",width:"16",height:"16",children:Object(a.jsx)("path",{d:"M416 128L192 384l-96-96"})})},R=function(){return Object(a.jsx)("svg",{viewBox:"0 0 512 512",width:"16",height:"16",children:Object(a.jsx)("path",{d:"M289.94 256l95-95A24 24 0 00351 127l-95 95-95-95a24 24 0 00-34 34l95 95-95 95a24 24 0 1034 34l95-95 95 95a24 24 0 0034-34z"})})},T=(n(172),function(e){Object(m.a)(n,e);var t=Object(g.a)(n);function n(e){var a;return Object(u.a)(this,n),(a=t.call(this,e)).taskId=e.match.params.id,a.task=k.tasks.find((function(e){return e.id===a.taskId})),a.urlBuilder=new j,a}return Object(p.a)(n,[{key:"renderPaper",value:function(e,t){return t?e?Object(a.jsx)("a",{href:e,target:"_blank",rel:"noopener noreferrer",children:t}):{paper_title:t}:""}},{key:"renderModelName",value:function(e,t){return e?Object(a.jsx)("a",{href:this.urlBuilder.buildDatasetUrl({id:t}),children:e}):""}},{key:"renderSourceLink",value:function(e){return e?Object(a.jsx)("a",{href:e,target:"_blank",rel:"noopener noreferrer",children:Object(a.jsx)(w,{})}):""}},{key:"renderModelRow",value:function(e){var t=e.dataset_name,n=e.dataset_id,i=e.model_name,s=e.paper_title,r=e.paper_link,o=e.source_link;return Object(a.jsxs)("tr",{children:[Object(a.jsx)("td",{children:Object(a.jsx)("a",{href:this.urlBuilder.buildDatasetUrl({id:n}),children:t})}),Object(a.jsx)("td",{children:this.renderModelName(i,n)}),Object(a.jsx)("td",{children:this.renderPaper(r,s)}),Object(a.jsx)("td",{children:this.renderSourceLink(o)})]},i)}},{key:"renderTaskDatasets",value:function(e){var t=this;return e&&0!==e.length?Object(a.jsxs)("table",{className:"table",children:[Object(a.jsx)("thead",{children:Object(a.jsxs)("tr",{children:[Object(a.jsx)("td",{children:"Dataset"}),Object(a.jsx)("td",{children:"Best model"}),Object(a.jsx)("td",{children:"Paper"}),Object(a.jsx)("td",{children:"Code"})]})}),Object(a.jsx)("tbody",{children:e.map((function(e){return t.renderModelRow(e)}))})]}):Object(a.jsx)("p",{children:"There are no submissions for this task."})}},{key:"render",value:function(){var e=this.task.datasets;return Object(a.jsxs)("div",{className:"task-details",children:[Object(a.jsx)("h3",{children:this.task.task_name}),Object(a.jsx)("p",{className:"task-description",children:this.task.task_description}),Object(a.jsx)("h4",{children:" Benchmarks"}),this.renderTaskDatasets(e)]})}}]),n}(s.a.Component)),_=n(20),L=n(42),S=n.n(L),P=n(240),C=(n(215),n(29)),N=function(e){Object(m.a)(n,e);var t=Object(g.a)(n);function n(e){var a;return Object(u.a)(this,n),(a=t.call(this,e)).svgRef=s.a.createRef(),a}return Object(p.a)(n,[{key:"componentDidMount",value:function(){var e=this.props,t=e.timeRange,n=e.dataPoints,a=e.width,i=e.height;this.drawScatterPlot(t,n,a,i)}},{key:"componentDidUpdate",value:function(){var e=this.props,t=e.timeRange,n=e.dataPoints,a=e.width,i=e.height;this.drawScatterPlot(t,n,a,i)}},{key:"drawScatterPlot",value:function(e,t,n,a){var i=Object(C.f)(this.svgRef.current).attr("width",n).attr("height",a);i.selectAll("*").remove();var s=function(e){return e.score},r=60,o=150,l=n-o-40,c=a-r-88,d=Object(C.e)().domain(e).range([0,l]),h=Object(C.d)().domain(Object(C.c)(t,s)).range([c,0]).nice(),u=i.append("g").attr("transform","translate(".concat(o,",").concat(r,")")),p=Object(C.a)(d).tickSize(-c).tickPadding(15),m=Object(C.b)(h).tickSize(-l).tickPadding(10),g=u.append("g").call(m);g.selectAll(".domain").remove(),g.append("text").attr("class","axis-label").attr("y",-55).attr("x",-c/2).attr("fill","black").attr("transform","rotate(-90)").attr("text-anchor","middle").text("Score");var b=u.append("g").call(p).attr("transform","translate(0,".concat(c,")"));b.select(".domain").remove(),b.append("text").attr("class","axis-label").attr("y",50).attr("x",l/2).attr("fill","black").text("Submission date");var f=Object(C.f)(".canvas").append("div").style("opacity",0).attr("class","tooltip").style("background-color","white").style("border","solid").style("border-width","1px").style("border-radius","5px").style("padding","10px");u.selectAll("circle").data(t).enter().append("circle").attr("cy",(function(e){return h(s(e))})).attr("cx",(function(e){return d(function(e){return e.submissionDate}(e))})).attr("r",5).on("mouseover",(function(e,t){return f.style("opacity",1).html("<b>".concat(t.model,"</b>: ").concat(s(t)))})).on("mousemove",(function(e){var t=e.clientX+10,n=e.clientY;return f.style("left","".concat(t,"px")).style("top","".concat(n,"px"))})).on("mouseleave",(function(){return f.transition().duration(200).style("opacity",0)})),u.append("text").attr("class","title").attr("x",l/2).attr("y",-30).attr("text-anchor","middle").text("Task leaderboard")}},{key:"render",value:function(){return Object(a.jsx)(a.Fragment,{children:Object(a.jsx)("svg",{ref:this.svgRef})})}}]),n}(i.Component),D=function(e){Object(m.a)(n,e);var t=Object(g.a)(n);function n(e){var a;return Object(u.a)(this,n),(a=t.call(this,e)).buildDataPoints=function(e){return a.dataset.data_points.map((function(t){return{model:t.model,submissionDate:t.submission_date,score:t[e]}}))},a.dataset=e.dataset,a.handleSelectedMetricChange=a.handleSelectedMetricChange.bind(Object(_.a)(a)),a.canvas=s.a.createRef(),a.onWindowResize=a.onWindowResize.bind(Object(_.a)(a)),a.state={timeRange:a.dataset.time_range,dataPoints:a.buildDataPoints(a.dataset.preferred_metric),width:void 0,height:void 0},a}return Object(p.a)(n,[{key:"componentDidMount",value:function(){window.addEventListener("resize",this.onWindowResize),this.onWindowResize()}},{key:"componentWillUnmount",value:function(){window.removeEventListener("resize",this.onWindowResize)}},{key:"onWindowResize",value:function(){var e=this.canvas.current.getBoundingClientRect();this.setState({width:e.width,height:e.height})}},{key:"handleSelectedMetricChange",value:function(e){var t=e.target.value;t&&this.setState({dataPoints:this.buildDataPoints(t)})}},{key:"render",value:function(){return Object(a.jsxs)(a.Fragment,{children:[Object(a.jsx)("div",{ref:this.canvas,className:"canvas",children:Object(a.jsx)(N,{timeRange:this.state.timeRange,dataPoints:this.state.dataPoints,width:this.state.width,height:this.state.height})}),Object(a.jsxs)("div",{id:"select-metric-group",className:"input-group input-group-sm",children:[Object(a.jsx)("div",{className:"input-group-prepend",children:Object(a.jsx)("label",{className:"input-group-text",htmlFor:"metrics",children:"View scores for:"})}),Object(a.jsx)("select",{className:"custom-select",name:"metrics",defaultValue:this.dataset.preferred_metric,onChange:this.handleSelectedMetricChange,children:this.dataset.metrics.map((function(e){return Object(a.jsx)("option",{value:e,children:e},e)}))})]})]})}}]),n}(i.Component),M=n(93),U=n(56),A=(n(217),function(e){Object(m.a)(n,e);var t=Object(g.a)(n);function n(e){var a;return Object(u.a)(this,n),(a=t.call(this,e)).models=e.models,a.metrics=e.metrics,a.state={sortDirection:"default",sortBy:"default"},a.onSort=a.onSort.bind(Object(_.a)(a)),a.sortFunction=a.sortFunction.bind(Object(_.a)(a)),a}return Object(p.a)(n,[{key:"onSort",value:function(e){var t,n=this.state.sortDirection;"default"===n&&(t="descending"),"descending"===n&&(t="ascending"),"ascending"===n&&(t="default"),this.setState({sortDirection:t,sortBy:e})}},{key:"sortFunction",value:function(e,t){var n=this.state,a=n.sortDirection,i=n.sortBy,s=e.results[i],r=t.results[i];return"ascending"===a?s-r:"descending"===a?r-s:0}},{key:"renderModel",value:function(e,t){return Object(a.jsxs)("tr",{children:[Object(a.jsx)("td",{children:t}),Object(a.jsx)("td",{children:e.model}),this.metrics.map((function(t){return Object(a.jsx)("td",{children:e.results[t]})})),Object(a.jsx)("td",{className:"td-extra-training-data",children:e.extra_training_data?Object(a.jsx)(x,{}):Object(a.jsx)(R,{})}),Object(a.jsx)("td",{children:e.model_size}),Object(a.jsx)("td",{children:Object(a.jsx)("a",{href:e.paper_link,target:"_blank",rel:"noopener noreferrer",children:e.paper_title})}),Object(a.jsx)("td",{children:e.source_link&&Object(a.jsx)("a",{href:e.source_link,target:"_blank",rel:"noopener noreferrer",children:Object(a.jsx)(w,{})})}),Object(a.jsx)("td",{children:e.submission_date})]})}},{key:"renderSortButton",value:function(){var e=this.state.sortDirection;return"ascending"===e?Object(a.jsx)(U.c,{}):"descending"===e?Object(a.jsx)(U.b,{}):Object(a.jsx)(U.a,{})}},{key:"render",value:function(){var e=this;return Object(a.jsxs)("table",{className:"table dataset-details",children:[Object(a.jsx)("thead",{children:Object(a.jsxs)("tr",{children:[Object(a.jsx)("td",{children:"Rank"}),Object(a.jsx)("td",{children:"Model"}),this.metrics.map((function(t){return Object(a.jsxs)("td",{children:[t,Object(a.jsx)("button",{type:"button",onClick:function(){return e.onSort(t)},children:e.renderSortButton()})]})})),Object(a.jsx)("td",{children:"Extra training data"}),Object(a.jsx)("td",{children:"Model size"}),Object(a.jsx)("td",{children:"Paper"}),Object(a.jsx)("td",{children:"Code"}),Object(a.jsx)("td",{children:"Submitted"})]})}),Object(a.jsx)("tbody",{children:Object(M.a)(this.models).sort(this.sortFunction).map((function(t,n){return e.renderModel(t,n)}))})]})}}]),n}(s.a.Component)),E=n(18),F=function(e){Object(m.a)(n,e);var t=Object(g.a)(n);function n(e){var a;return Object(u.a)(this,n),(a=t.call(this,e)).datasetId=e.match.params.id,a.dataset=E.datasets.find((function(e){return e.id===a.datasetId})),a.urlBuilder=new j,a.state={infoVisible:!1},a.toggleDatasetInfo=a.toggleDatasetInfo.bind(Object(_.a)(a)),a}return Object(p.a)(n,[{key:"toggleDatasetInfo",value:function(){var e=this.state.infoVisible;this.setState({infoVisible:!e})}},{key:"renderMoreInfoText",value:function(){return this.state.infoVisible?Object(a.jsxs)("span",{children:["Hide details ",Object(a.jsx)(P.a,{})]}):Object(a.jsxs)("span",{children:["More details ",Object(a.jsx)(P.b,{})]})}},{key:"render",value:function(){return Object(a.jsxs)(a.Fragment,{children:[Object(a.jsx)("h3",{className:"dataset-title",children:this.dataset.dataset_name}),Object(a.jsx)("div",{className:"dataset-description",children:S()(this.dataset.dataset_description)}),Object(a.jsx)("table",{className:"dataset-info",children:Object(a.jsxs)("tbody",{children:[Object(a.jsxs)("tr",{children:[Object(a.jsx)("th",{children:"Source"}),Object(a.jsx)("td",{children:Object(a.jsx)("a",{href:this.dataset.dataset_link,target:"_blank",rel:"noopener noreferrer",children:this.dataset.dataset_link})})]}),Object(a.jsxs)("tr",{children:[Object(a.jsx)("th",{children:"License"}),Object(a.jsx)("td",{children:this.dataset.license_url?Object(a.jsx)("a",{href:this.dataset.license_url,target:"_blank",rel:"noopener noreferrer",children:this.dataset.license}):this.dataset.license})]})]})}),Object(a.jsxs)("div",{children:[Object(a.jsx)("div",{onClick:this.toggleDatasetInfo,className:"collapse-trigger",children:this.renderMoreInfoText()}),Object(a.jsx)(b.Collapse,{isOpened:this.state.infoVisible,children:Object(a.jsx)("div",{children:S()(this.dataset.dataset_info)})})]}),Object(a.jsx)("div",{className:"add-model-link",children:Object(a.jsx)("a",{href:j.submitPageUrl,children:"Add model"})}),Object(a.jsx)(D,{dataset:this.dataset}),Object(a.jsx)(A,{models:this.dataset.models,metrics:this.dataset.metrics})]})}}]),n}(s.a.Component),B=(n(218),function(){return Object(a.jsxs)(a.Fragment,{children:[Object(a.jsx)("h1",{children:"Who are we?"}),Object(a.jsx)("p",{children:"We are a group of Romanians with expertise in Machine Learning, NLP, linguistics, and data privacy. Our goal is to accelerate progress in AI research on Romanian language tasks."}),Object(a.jsxs)("h1",{children:["What is the LiRo (",Object(a.jsx)("em",{children:"Limba Rom\xe2n\u0103"}),") project?"]}),Object(a.jsx)("h2",{children:"Benchmark"}),Object(a.jsxs)("p",{children:["LiRo provides a benchmark for Romanian language tasks. It contains ",k.tasks.length," tasks on"," ",E.datasets.length," datasets: ",k.tasks.length," existing in the literature, ",0," newly created through our team\u2019s efforts."]}),Object(a.jsx)("h2",{children:"Leaderboard"}),Object(a.jsx)("p",{children:"LiRo keeps track of performance of different published models on the datasets and tasks listed above. This allows easy comparison of different models and monitoring progress on these tasks and datasets over time."}),Object(a.jsx)("h2",{children:"Starter code"}),Object(a.jsx)("p",{children:"Contains scripts for downloading the datasets and computing various metrics for the tasks listed above. As this project is ongoing, we will add as soon as possible starter code for tasks that do not yet have it."}),Object(a.jsx)("h1",{children:"How can you contribute?"}),Object(a.jsxs)("p",{children:["To add your model to the leaderboard, use the starter code to evaluate your model\u2019s performance and"," ",Object(a.jsx)("a",{href:j.submitPageUrl,children:"submit"})," your results, together with the paper and/or GitHub repo."]}),Object(a.jsx)("p",{children:"If you have a relevant dataset that is not included, please contact us to see how we can add it to the leaderboard. The more the better."}),Object(a.jsx)("h1",{children:"Team"}),Object(a.jsxs)("ul",{children:[Object(a.jsx)("li",{children:"Adriana Stan, Associate Professor (Technical University of Cluj-Napoca)"}),Object(a.jsx)("li",{children:"Andrei-Marius Avram, MSc student (Politehnica University of Bucharest)"}),Object(a.jsx)("li",{children:"Andrei Pruteanu, NLP Independent Researcher"}),Object(a.jsx)("li",{children:"Be\xe1ta L\u0151rincz, PhD student (\u201dBabe\u0219-Bolyai\u201d University, Technical University of Cluj-Napoca)"}),Object(a.jsx)("li",{children:"Cristina Victoria Iacobescu, Attorney-at-law, Reff & Associates (member of Deloitte Legal)"}),Object(a.jsx)("li",{children:"Gabriel Marchidan, (Feel IT Services, AIRomania)"}),Object(a.jsx)("li",{children:"George-Andrei Dima, MSc student (Politehnica University of Bucharest)"}),Object(a.jsx)("li",{children:"Lorena Ro\u0219ia, Attorney-at-law, Reff & Associates (member of Deloitte Legal)"}),Object(a.jsx)("li",{children:"Luciana Morogan, Associate Professor (Military Technical Academy Ferdinand Bucharest)"}),Object(a.jsx)("li",{children:"Madalina Chitez, Researcher (West University of Timisoara, CODHUS Research Centre)"}),Object(a.jsx)("li",{children:"Mihai Ilie, NLP Independent Researcher"}),Object(a.jsx)("li",{children:"Petru Rebeja, PhD student (Alexandru Ioan Cuza University of Ia\u0219i, AIRomania)"}),Object(a.jsx)("li",{children:"Radu Tudor Ionescu (University of Bucharest)"}),Object(a.jsx)("li",{children:"Razvan Pascanu, Research Scientist (DeepMind, EEML, AIRomania)"}),Object(a.jsx)("li",{children:"\u0218tefan Daniel Dumitrescu, NLP Independent Researcher"}),Object(a.jsx)("li",{children:"Traian Rebedea, Associate Professor (Politehnica University of Bucharest)"}),Object(a.jsx)("li",{children:"Viorica Patraucean, Research Scientist (DeepMind, EEML, AIRomania)"})]})]})}),I=(n(219),n(51)),z=function(){return Object(a.jsxs)(a.Fragment,{children:[Object(a.jsx)("h1",{id:"guide-on-how-to-submit-a-new-model",children:"Guide on how to submit a new model"}),Object(a.jsxs)("p",{children:["Submitting a new model to the leaderboard is easy! Simply"," ",Object(a.jsx)("a",{href:"https://github.com/eemlcommunity/ro_benchmark_leaderboard/issues/new/choose",children:"create a new issue"})," and click on the ",Object(a.jsx)("code",{children:"Get started"})," button to the right of the ",Object(a.jsx)("code",{children:"Submit new model"})," template. Please fill in with all the info requested in the template, as well as all extra info you wish to let us know about your model. We\u2019ll review your submission and add it to the leaderboard, that\u2019s it!"]}),Object(a.jsx)("p",{children:"Here\u2019s a step-by-step guide on how to add a new model. Let\u2019s assume you have a new Named Entity Recognition (NER) model that you wish to submit; after starting a new model issue template, you\u2019ll have to fill in a number of fields:"}),Object(a.jsxs)("ul",{children:[Object(a.jsx)("li",{children:Object(a.jsxs)("p",{children:[Object(a.jsx)("code",{children:"Model name"})," Please write here your model name. If you didn\u2019t name your model, you\u2019d help the community a lot by writing here the underlying models/methods used. For example, if your NER model model is based on a BERT and a CRF on top, please write it as ",Object(a.jsx)("code",{children:"BERT + CRF"}),". Or if it is an ensemble of LSTMs, write ",Object(a.jsx)("code",{children:"RNN Ensemble"}),", etc."]})}),Object(a.jsx)("li",{children:Object(a.jsxs)("p",{children:[Object(a.jsx)("code",{children:"Task(s)"})," Please write here the task that your model participates in. For example, you would write here ",Object(a.jsx)("code",{children:"NER"})]})}),Object(a.jsx)("li",{children:Object(a.jsxs)("p",{children:[Object(a.jsx)("code",{children:"Dataset(s)"})," Please write here the datasets your model trains/runs on. For example"," ",Object(a.jsx)("code",{children:"RONEC - Romanian Named Entity Corpus v1"}),". Please list here ",Object(a.jsx)("strong",{children:"all"})," the datasets you have run your model on."]})}),Object(a.jsx)("li",{children:Object(a.jsxs)("p",{children:[Object(a.jsx)("code",{children:"External training data"})," Yes/No if your model was trained on external data. Any training data that is ",Object(a.jsx)("em",{children:"not"})," in the dataset you are submitting results to, and you have used to train your model on, will automatically lead to a ",Object(a.jsx)("code",{children:"Yes"})," at this question. ",Object(a.jsx)("em",{children:"Note"}),": pretrained transformers (or any other general, non-task/dataset oriented pretraining) does not count as external training data."]})}),Object(a.jsx)("li",{children:Object(a.jsxs)("p",{children:[Object(a.jsx)("code",{children:"Model size"})," ",Object(a.jsx)("em",{children:"[Optional]"})," Please write here the number of parameters in millions. Eg, if you used a BERT-base and a CRF, you\u2019d probably write ",Object(a.jsx)("code",{children:"110M"}),". It\u2019s very easy to count the number of parameters. Practically, in all current ML plaforms, getting this number is one line of code."]})}),Object(a.jsx)("li",{children:Object(a.jsxs)("p",{children:[Object(a.jsx)("code",{children:"Paper title"})," ",Object(a.jsx)("em",{children:"[Optional]"})," If you have a published paper, list name here."]})}),Object(a.jsx)("li",{children:Object(a.jsxs)("p",{children:[Object(a.jsx)("code",{children:"Paper link"})," ",Object(a.jsx)("em",{children:"[Optional]"})," input URL here; e.g.\xa0link to arxiv.org paper>"]})}),Object(a.jsx)("li",{children:Object(a.jsxs)("p",{children:[Object(a.jsx)("code",{children:"Source code"})," ",Object(a.jsx)("em",{children:"[Optional]"})," input link to Github or other code repository here>"]})}),Object(a.jsx)("li",{children:Object(a.jsxs)("p",{children:[Object(a.jsx)("code",{children:"Results"}),": Please list your model\u2019s metrics/results, one per line, like:"," ",Object(a.jsx)("code",{children:"[Dataset], [Metric], [Value]"}),"."]})})]}),Object(a.jsx)("h2",{id:"example-submission",children:"Example submission:"}),Object(a.jsx)("pre",{children:Object(a.jsxs)("code",{children:["Model name: BERT + CRF",Object(a.jsx)("br",{}),"Task(s): NER",Object(a.jsx)("br",{}),"Dataset(s): RONEC - Romanian Named Entity Corpus v1",Object(a.jsx)("br",{}),"External training data: No",Object(a.jsx)("br",{}),"Model size: 110M",Object(a.jsx)("br",{}),"Paper title: (no paper yet)",Object(a.jsx)("br",{}),"Paper link: -",Object(a.jsx)("br",{}),"Source code: http://github.com/username/my_ner_repo",Object(a.jsx)("br",{}),Object(a.jsx)("br",{}),"Results:",Object(a.jsx)("br",{}),"RONEC - Romanian Named Entity Corpus v1, F1, 91.50",Object(a.jsx)("br",{}),"RONEC - Romanian Named Entity Corpus v1, Precision, 92.00",Object(a.jsx)("br",{}),"RONEC - Romanian Named Entity Corpus v1, Recall, 91.00"]})}),Object(a.jsx)("h2",{id:"other-considerations",children:"Other considerations:"}),Object(a.jsx)("ul",{children:Object(a.jsxs)("li",{children:["If you have sumbitted a model to this leaderboard, ",Object(a.jsx)("strong",{children:"but"})," your paper was not published at the time, reopen the issue an let us know about the paper (title + link). Similarly, reopen your issue regarding source code availability, or any other changes you need to make to your submission."]})}),Object(a.jsx)("hr",{}),Object(a.jsx)(I.a,{variant:"primary",href:"https://github.com/eemlcommunity/ro_benchmark_leaderboard/issues/new/choose",children:"Submit your model"})]})},q=(n(220),function(){return Object(a.jsxs)(a.Fragment,{children:[Object(a.jsx)("h1",{children:"Terms and conditions"}),Object(a.jsx)("p",{children:"These terms and conditions, as may be amended from time to time, apply to the LiRo benchmark project organized by the team of LiRo volunteers (hereinafter referred to as \u201cLiRo Team\u201d) with the aim to accelerate progress in AI research on Romanian language (hereinafter referred to as \u201cLiRo Benchmark\u201d) and to the our website and all the resources available therein, such as starter codes, leaderboards (\u201cLiRo Platform\u201d)."}),Object(a.jsx)("p",{children:"By accessing, browsing and using the LiRo Platform and/or by making a submission to the LiRo Benchmark, you acknowledge and agree to have read, understood and agreed to the terms and conditions set out below (including the Privacy Statement), as they may be amended from time to time:"}),Object(a.jsx)("h2",{children:"1. Accessing and browsing the LiRo Platform"}),Object(a.jsx)("p",{children:"You agree to access and browse the LiRo Platform only in good faith and for a purpose permitted under the applicable law and at all-time comply with these terms and conditions."}),Object(a.jsx)("h2",{children:"2. LiRo Benchmark rules"}),Object(a.jsx)("p",{children:"As organizer of the LiRo Benchmark, LiRo Team discretionary decides the (i) type of challenges, metrics and databases on which the LiRo Benchmark will run, (ii) the deadline and format of benchmark submissions, (iv) the evaluation software and criteria that it will use (\u201cLiRo Evaluation Tool\u201d), (iv) publication format of the submission and the evaluation results; and (v) the calendar and the prizes, if applicable for a particular competition, and any other specific rules for the organization of the LiRo Benchmark (jointly hereinafter the \u201cLiRo Benchmark Rules\u201d)."}),Object(a.jsx)("p",{children:"The LiRo Benchmark Rules are reflected in the LiRo Platform pages. LiRo Team reserves the discretionary right to amend and alter the LiRo Benchmark Rules and the LiRo Evaluation Tool, at any moment in time, as it will see fit, and to this end it will updated the LiRo Platform, having no obligation to notify you of such changes."}),Object(a.jsx)("h2",{children:"3. Submission to the LiRo benchmark"}),Object(a.jsx)("p",{children:"By submitting an application to the LiRo Benchmark, you agree to these terms and condition and to LiRo Team evaluating and rating the performance of your AI software against the performance of other submissions leveraging the LiRo Evaluation Tool and the LiRo Benchmark Rules, in the form applicable at your submission date."}),Object(a.jsx)("p",{children:"Once you submit an application, you agree it will be published in the LiRo Platform, together with the evaluation results, as they may be updated from time to time. You agree that, unless we receive a removal request from you as per section 4 below, the submission may be public on the LiRo Platform for an indefinite period, unless LiRo Team discretionary decides otherwise."}),Object(a.jsx)("p",{children:"You understand that you will not receive any compensation of any kind for the submission, unless otherwise mentioned expressly in the LiRo Platform and in all cases subject to the specific terms and conditions mentioned therein."}),Object(a.jsx)("p",{children:"By uploading a submission you accept full legal and moral responsibility of any and all legal claims that are made by any third parties due to LiRo Team publishing and using the submission."}),Object(a.jsx)("p",{children:"LiRo Team does not own or endorse the submissions that are uploaded. The truthfulness, validity and right to use of the submission is assumed by the person who submitted the application, and is not the responsibility of LiRo Team."}),Object(a.jsx)("p",{children:"LiRo Team disclaims all responsibility and liability for the submission. You warrant that the submission shall not contain any viruses, Trojan horses or infected files and shall not contain any pornographic, illegal, obscene, insulting, objectionable or inappropriate material and does not infringe any third party (intellectual property right, copyright or privacy) rights. Any submission that does not meet the aforesaid criteria will not be posted and/or can be removed/deleted by LiRo Team at any time and without prior notice."}),Object(a.jsx)("p",{children:"Upon a change in the LiRo Evaluation Tool and the LiRo Benchmark Rules, your submission will be reevaluated and the updated results will be published on the LiRo platform."}),Object(a.jsx)("h2",{children:"4. Removing a submission from the LiRo benchmark"}),Object(a.jsx)("p",{children:"To remove a submission from the LiRo Platform, please write an email to: liro.benchmark@gmail.com and we will remove you submission promptly. The license you grant to LiRo Team through these terms and conditions shall not cease upon receipt of a removal request from you which shall have as effect only the removal of your submission from the LiRo Platform."}),Object(a.jsx)("h2",{children:"5. Intellectual Property"}),Object(a.jsx)("h3",{children:"5.1. LiRo Benchmark and LiRo Platform"}),Object(a.jsx)("p",{children:"Unless stated otherwise in the LiRo Platform, the software used in the LiRo Benchmark or available at or used by the LiRo Platform and the intellectual property rights (including the copyrights) of the contents and information of and material on the LiRo Platform are owned by LiRo Team and its volunteers."}),Object(a.jsx)("p",{children:"LiRo Team and its volunteers exclusively retains ownership of all rights, title and interest in and to (all intellectual property rights of) (the look and feel (including infrastructure) of) the LiRo Platform and the LiRo Benchmark (including the LiRo Evaluation Tool, the LiRo Benchmark Rules, the starter code made available on the LiRo Platform) (\u201cLiRo IP\u201d)."}),Object(a.jsx)("p",{children:"You are entitled to copy, scrape, publish, promote, integrate, utilize, combine or otherwise use the LiRo IP for scientific research purposes only. Any other use of the LiRo IP requires our prior written approval."}),Object(a.jsx)("h3",{children:"5.2. LiRo brand and trademark"}),Object(a.jsx)("p",{children:"LiRo image, brand, brand elements and trademarks may be used only with LiRo Team\u2019s prior written consent."}),Object(a.jsx)("h3",{children:"5.3. Benchmark databases"}),Object(a.jsx)("p",{children:"The intellectual property rights and the license on the benchmark databases indicated on the LiRo Platform are the ones indicated in the license page of each database and you agree to fully respect the applicable license terms and conditions and to indemnify LiRo Team and any of its volunteers for any damages caused by your failure to comply with the applicable license for the benchmark databases."}),Object(a.jsx)("h3",{children:"5.4. Your submission to the LiRo Benchmark"}),Object(a.jsx)("p",{children:"By submitting an application in the LiRo benchmark, you certify, warrant and agree that you own the copyright to your entire submission and you hereby grant LiRo Team the right (i) run the LiRo Evaluation Tool on your submission and (ii) to use, reproduce, publish, display, have reproduced, distribute, sublicense, communicate, make derivative works and make available any part or the entire submission, including your name, results and the evaluation results, on the LiRo Platform and in any (online/offline) promotional and scientific materials and publications and as LiRo Team at its discretion sees fit."}),Object(a.jsx)("p",{children:"The license you grant herein is irrevocable, unconditional, unlimited in time and territory, free of charge and it is for the benefit of any member of the LiRo Team. You hereby grant LiRo Team the right to sublicense any and all of the rights it has received herein to any third party, as LiRo Team will see fit, provided that the sublicense will comply of the terms of the license herein."}),Object(a.jsx)("h2",{children:"6. Data protection"}),Object(a.jsx)("p",{children:"You agree to process the personal data part of the LiRo Benchmark Project in capacity as independent controller, and in compliance with the relevant and applicable data protection laws (i.e., including but not limited to Regulation 2016/679 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC)."}),Object(a.jsx)("h2",{children:"7. Disclaimers and liability limitations"}),Object(a.jsx)("p",{children:"To the extent permitted by the applicable law, LiRo Team and its volunteers hereby disclaim any and all liability related to the use of LiRo Platform, LiRo Benchmark and LiRo Evaluation Tool, which are made available AS-IS, on a no reliance basis, without warranties of any kind, either expressed or implied."}),Object(a.jsx)("p",{children:"LiRo Team does not warrant that the functions or content contained in the LiRo Platform will be uninterrupted or error-free, that defects will be corrected, or that the LiRo Platform or the server that makes it available are free of viruses or other harmful components. LiRo IP may include technical inaccuracies or typographical errors, and LiRo Team may make changes or improvements at any time. LiRo Team does not represent or warrant that the information accessible via the LiRo Platform or the LiRo Benchmark is accurate, complete, or current."}),Object(a.jsx)("p",{children:"You assume full responsibility and risk of loss resulting from your use of the LiRo Platform and Liro benchmark. Under no circumstances will LiRo Team, its volunteers, licensors, service providers, content providers, employees, agents, officers, directors, and contractors (\u201cLIRO TEAM Related Parties\u201d) will be liable for any incidental, direct, indirect, punitive, actual, consequential, special, exemplary, or other damages, including loss of revenue or income, pain and suffering, emotional distress, or similar damages, even if they have been advised of the possibility of such damages."}),Object(a.jsx)("p",{children:"LiRo Team disclaims expressly any liability for any decisions made on the basis of information published on LiRo Platform, or in relation to the manner in which your submission, the information and the databases published on the LiRo Platform are used by third parties."}),Object(a.jsx)("h2",{children:"8. Indemnification"}),Object(a.jsx)("p",{children:"You will indemnify and hold LiRo Team and LiRo Team Related Parties harmless from any loss arising from your breach of these terms and conditions, including any use of content other than as expressly authorized in these terms and conditions. You agree that the LiRo Team and LiRo Team Related Parties will have no liability in connection with any such breach or unauthorized use, and you agree to indemnify LiRo Team and LiRo Team Related Parties from any and all resulting loss, damages, judgments, awards, costs, expenses, and attorneys' fees in connection therewith. You will also indemnify and hold LiRo Team and LiRo Team Related Parties harmless from and against any claims brought by third parties arising out of your use of the information, databases, software accessed on or from the LiRo Platform."}),Object(a.jsx)("h2",{children:"9. Investigations"}),Object(a.jsx)("p",{children:"LiRo Team has the right to investigate suspected violations of these terms and conditions and will cooperate fully with any law enforcement authorities or court order requesting or directing us to disclose the identity of anyone using or accessing the LiRo Platform in a manner believed to violate these terms and conditions or applicable laws. By accepting these terms and conditions, you waive and hold harmless LiRo Team from any claims resulting from any action taken by us during or as a result of our investigations and/or from any actions taken as a consequence of investigations by either us or law enforcement authorities."}),Object(a.jsx)("h2",{children:"10. Cancelling access"}),Object(a.jsx)("p",{children:"LiRo Team reserves the right to deny access to the LiRo Platform or any features thereof to anyone who violates these terms and conditions or who, in its sole judgment, interferes with the ability of others to enjoy the LiRo Platform or infringes the rights of others. LiRo Team may terminate or suspend your use of the LiRo Platform at any time without cause and without any liability to you."}),Object(a.jsx)("h2",{children:" 11. Site changes and termination"}),Object(a.jsx)("p",{children:"LiRo Team reserves the right at any time and from time to time to modify or discontinue, temporarily or permanently, the LiRo Platform, or any portion thereof, with or without notice. You agree that LiRo Team will not be liable to you or to any third party for any modification, suspension, or discontinuance of the LiRo Platform or any portion thereof, including in the situation where your submission is no longer published."}),Object(a.jsx)("h2",{children:"12. Outgoing and Incoming Links"}),Object(a.jsx)("p",{children:"The LiRo platform may include hyperlinks to other sites (\u201cLinked Sites\u201d) and other sites may link to the LiRo Platform. Such linking is not an indication that the Linked Sites are maintained by, related to, sponsored by or affiliated with the LiRo Platform or with LiRo Team; an indication that LiRo Team has reviewed any or all of such Linked Sites; or an indication that LiRo Team is responsible for the content of those Linked Sites even if they are owned or run by our volunteers and/or partners. LiRo Team provides links to Linked Sites as a service and courtesy to visitors to the LiRo Platform. Hyperlinks are to be accessed at your own risk, and LiRo Team makes no representations or warranties about the content, completeness, or accuracy of these hyperlinks or the Linked Sites."}),Object(a.jsx)("h2",{children:"13. Links to LiRo Platform"}),Object(a.jsx)("p",{children:"You may hyperlink to the homepage or any other page of the LiRo platform; however, you may not (and may not authorize any other party) to (i) co-brand the LiRo Platform or (ii) frame the LiRo platform without our express prior written permission. For purposes of these terms and conditions, \u201cco-branding\u201d means to display a name, logo, trademark, or other means of attribution or identification of any party in such a manner as is reasonably likely to give a user the impression that such other party has the right to display, publish, or distribute the LiRo Platform or its content. You agree to cooperate with us in causing any unauthorized co-branding, framing, or hyper-linking immediately to cease."}),Object(a.jsx)("h2",{children:"14. Changes to Terms and Conditions"}),Object(a.jsx)("p",{children:"All content contained in the LiRo Platform is subject to change without notice. LiRo Team reserves the right to modify these terms and conditions and any policies affecting the LiRo Platform. Any modification is effective immediately following the posting of such changes on the LiRo Platform. Accordingly, you should periodically review these terms and conditions. By continuing to enter the LiRo Platform, you acknowledge and agree that you shall be bound by any such modifications."}),Object(a.jsx)("h2",{children:"15. Applicable Law & dispute resolution"}),Object(a.jsx)("p",{children:"These terms and conditions shall be governed by and construed in accordance with Romania law. Any dispute arising out of these terms and conditions shall exclusively be submitted to the competent courts in Bucharest, Romania."})]})}),G=(n(221),function(){return Object(a.jsxs)(a.Fragment,{children:[Object(a.jsx)("h1",{children:"Privacy Statement"}),Object(a.jsx)("p",{children:"LiRo Benchmark Project aims to process as little personal data as possible, and only in accordance with the data privacy principles and regulations (in particular, the EU General Data Protection Regulation (\u201cGDPR\u201d))."}),Object(a.jsx)("p",{children:"We are an independent structure of pro-bono volunteers with expertise in Machine Learning, NLP, linguistics and data privacy and our goal is to accelerate progress in AI research on Romanian language (referred to as \u201cwe\u201d, \u201cour\u201d, \u201ccontroller\u201d)."}),Object(a.jsx)("p",{children:"This Privacy Statement applies to any person involved in the LiRo Benchmark Project."}),Object(a.jsx)("h2",{children:"What personal data do we process? For which purposes do we process such data?"}),Object(a.jsx)("h3",{children:"If you are a user of the Benchmark, Leaderboard or Starter Code, we process the following:"}),Object(a.jsx)("p",{children:"As far as we are concerned, you can submit your model without providing us any personal data."}),Object(a.jsxs)("ul",{children:[Object(a.jsx)("li",{children:"However, in order to be able to allocate the tasks\u2019 performance to your model and to maintain a record of such activities, we will process personal data in the form of certain unique identifiers used by our systems only for this purpose (e.g., user ID, GitHub ID)."}),Object(a.jsx)("li",{children:"Also, depending on the results of your model and on how we will develop further LiRo Benchmark Project (e.g., as an award-based competition) we may ask you to provide us with certain personal data in the form of identification details (e.g., name, surname) and contact details (e.g., email, phone number). We will use such identification details and contact details only in order to be able to contact you for functional enquiries (e.g., errors on models, additional questions on performance etc.) or to contact you for granting the award."})]}),Object(a.jsx)("p",{children:"We will process your personal data based on our legitimate interest to perform scientific research regarding the acceleration of progress in AI on Romanian language (article 6 (1) f) GDPR), or as it is necessary for the performance of our obligations to you (article 6 (1) b) GDPR). If you refuse to provide us with the personal data necessary for functional enquiries or for award granting, we will not be able to provide you with such benefits."}),Object(a.jsx)("h3",{children:"If your personal data is found in the datasets, we process the following:"}),Object(a.jsx)("p",{children:"We will process the personal data found in the datasets only in order to develop tasks, track performance of different models on such datasets and compute metrics out of such performance. We will use only personal data that has been made public for information purposes, and we will further process it only for scientific research purposes that are deemed compatible with the initial purposes (article 5 (1) b) GDPR)."}),Object(a.jsx)("p",{children:"Examples of such datasets are - RONEC (Romanian Named Entity Corpus) and Romanian RRT Treebank. In the near future, we would like to obtain datasets from news agencies, and we will update this section as soon as possible. For specific details regarding the datasets used, please access the designated section on our website."}),Object(a.jsx)("p",{children:"We will process your personal data based on our legitimate interest to perform scientific research regarding the acceleration of progress in AI on Romanian language (article 6 (1) f) GDPR)."}),Object(a.jsx)("h3",{children:"If you are part of the independent structure of pro-bono volunteers who are making the LiRo Benchmark Project work smoothly, we thank you for this, and we process the following:"}),Object(a.jsx)("p",{children:"We will process your name, surname and contact details in order to communicate with you about the LiRo Benchmark Project (e.g., action points, implementation measures, assessments on potential issues, potential errors, schedule and hold meetings, article drafting, records retention etc.)."}),Object(a.jsx)("p",{children:"We will process your personal data based on our legitimate interest to perform scientific research regarding the acceleration of progress in AI on Romanian language (article 6 (1) f) GDPR)."}),Object(a.jsx)("h2",{children:"Which are the parties with which we will share your personal data?"}),Object(a.jsx)("p",{children:"As a rule, we will not share your personal data with third parties."}),Object(a.jsxs)("p",{children:["However, under exceptional circumstances we may share your data with:",Object(a.jsxs)("ul",{children:[Object(a.jsx)("li",{children:"third party services providers such as \u2013 translation offices, awards providers, cloud services providers, analytics services providers, security services providers, IT services providers (GitHub);"}),Object(a.jsx)("li",{children:"local or central public authorities, national institutions, regulators, courts of law (if requested);"}),Object(a.jsx)("li",{children:"any other third party to which such disclosure is expressly provided by the applicable laws."})]})]}),Object(a.jsx)("p",{children:"Generally, we do not transfer your personal data to non-EU countries. However, depending on the services providers used your personal data may be transferred to certain non-EU countries \u2013 more specifically, the United States of America. The transfer of your personal data to a third country is performed pursuant to implementing legally appropriate safeguards for the protection of your personal data (e.g., based on standard data protection clauses in accordance with article 46 GDPR)."}),Object(a.jsx)("h2",{children:"How long do we store your personal data?"}),Object(a.jsxs)("p",{children:["We process and store your personal data for the period necessary to perform scientific research regarding the acceleration of progress in AI on Romanian language, in accordance with the purposes mentioned under section \u201c",Object(a.jsx)("i",{children:"What personal data and for which purposes we process such data?"}),"\u201d"]}),Object(a.jsx)("h2",{children:"What are your rights related to personal data?"}),Object(a.jsxs)("p",{children:["You have the following data protection related rights, which you may exercise either individually or cumulatively:",Object(a.jsxs)("ol",{children:[Object(a.jsxs)("li",{children:[Object(a.jsx)("i",{children:"Access to your personal data"})," \u2013 you may obtain a confirmation that your personal data is processed by us, information regarding such personal data, as well as a copy of such personal data,"]}),Object(a.jsxs)("li",{children:[Object(a.jsx)("i",{children:"Correction of your personal data"})," \u2013 you may ask us to correct the incomplete or inaccurate personal data that we hold about you,"]}),Object(a.jsxs)("li",{children:[Object(a.jsx)("i",{children:"Restrict the processing of your personal data"})," - you may request us to suspend the processing of your personal data during (i) the establishment of its accuracy/complete character, (ii) the determination of whether our legitimate interests override your right to privacy, (iii) when the use of your data is unlawful, however you oppose to its erasure, and request the restriction of their use instead or (iv) we do no longer need the personal data for the purpose of the processing, but when you request the storage of such data only for establishing, exercising or defending legal claims."]}),Object(a.jsxs)("li",{children:[Object(a.jsx)("i",{children:"Object to the processing of your personal data"})," - you may request us to no longer process your personal data based on our legitimate interest when such processing affects your fundamental rights and freedoms. We must cease processing, unless we cannot demonstrate any compelling legitimate interest overriding your interests, rights and freedoms or unless we use such data for the establishment, exercise or defense of legal claims.",Object(a.jsxs)("p",{children:[Object(a.jsx)("i",{children:"Important Note"}),": The access, correction, restriction and objection related rights are not applicable for processing personal data for scientific research purposes, if exercising such rights would render impossible or seriously impair the achievement of the specific purposes. This means that if you exercise either of such rights, we will not be able to provide for an answer, if such would compromise the purpose of the LiRo Benchmark Project."]})]}),Object(a.jsxs)("li",{children:[Object(a.jsx)("i",{children:"Erase your personal data"})," - you may request the deletion or removal of the personal data that we hold about you, only in the cases expressly mentioned by the law (e.g., the data are no longer necessary for the processing purposes, unlawful processing, object to processing and no overriding interest exists etc.). However, we note that the exercise of such right is subject to certain exceptions that we may invoke in accordance with the law (e.g., the processing is necessary for the compliance with a legal obligation, for the establishment, exercise or defense of legal claims),",Object(a.jsxs)("p",{children:[Object(a.jsx)("i",{children:"Important Note"}),": The right to erase your personal data is not applicable to processing personal data for scientific research purposes. This means that if you exercise such right, we will not be able to provide for an answer."]})]}),Object(a.jsxs)("li",{children:[Object(a.jsx)("i",{children:"Port your personal data"})," - if we process your personal data by automated means and based on your consent of for the performance of a contract, you may request a copy of your data provided in a structured, commonly used, machine-readable format. You may request us to provide such data either directly to you, or to a third party."]}),Object(a.jsxs)("li",{children:[Object(a.jsx)("i",{children:"Additional rights pertaining to automated decisions"})," - n the case of automated decisions based on your personal data, you may request to (i) obtain human intervention with respect to such process, (ii) express your point of view with respect to such process, (iii) contest the decision pertaining to such process.",Object(a.jsxs)("p",{children:[Object(a.jsx)("i",{children:"Important Note"}),": Based on the ways in which the LiRo Benchmark Project is structured at this moment, the conditions that need to be fulfilled for you to exercise the right to port your data or not to be subject to automated decisions are not fulfilled."]})]})]})]}),Object(a.jsx)("p",{children:"If you wish to exercise any of the rights set out above, please contact us under the following email address liro.benchmark@gmail.com. Such exercise is free of charge, unless your request is clearly unfounded, repetitive or excessive, cases in which we may charge a reasonable fee or we may refuse to act on request."}),Object(a.jsx)("p",{children:"Moreover, you have the right to file a complaint with the National Data Protection Authority (in Romania \u2013 Autoritatea Nationala pentru Supravegherea Prelucrarii Datelor cu Caracter Personal) regarding any potential non-compliances pertaining to the processing of your personal data within the LiRo Benchmark Project."})]})}),W=(n(222),function(e){Object(m.a)(n,e);var t=Object(g.a)(n);function n(e){var a;return Object(u.a)(this,n),(a=t.call(this,e)).urlBuilder=new j,a}return Object(p.a)(n,[{key:"renderDataset",value:function(e){return Object(a.jsxs)("div",{className:"row dataset-row",children:[Object(a.jsx)("div",{className:"row dataset-title",children:Object(a.jsx)("h2",{children:Object(a.jsx)("a",{href:this.urlBuilder.buildDatasetUrl(e),children:e.dataset_name})})}),Object(a.jsx)("div",{className:"row dataset-description",children:S()(e.dataset_description)}),Object(a.jsx)("div",{className:"row dataset-info",children:Object(a.jsxs)("ul",{children:[Object(a.jsxs)("li",{children:[Object(a.jsx)("span",{children:"license:"})," ",e.license]}),Object(a.jsxs)("li",{children:[Object(a.jsx)("span",{children:"submissions:"})," ",e.models.length]}),Object(a.jsxs)("li",{children:[Object(a.jsx)("span",{children:"preferred metric:"})," ",e.preferred_metric]})]})})]})}},{key:"render",value:function(){var e=this;return Object(a.jsx)(a.Fragment,{children:Object(a.jsxs)("div",{className:"container",children:[Object(a.jsxs)("div",{className:"row header-row",children:[Object(a.jsx)("h1",{children:"Datasets"}),Object(a.jsxs)("p",{children:["LiRo Benchmark contains ",E.datasets.length," datasets. If you would like to submit another dataset please send us an email at ",Object(a.jsx)("a",{href:"mailto:contact@eeml.eu",children:"contact@eeml.eu"}),"."]})]}),E.datasets.map((function(t){return e.renderDataset(t)}))]})})}}]),n}(s.a.Component)),Y=function(e){var t=e.location;return Object(a.jsxs)(c.c,{location:t,children:[Object(a.jsx)(c.a,{exact:!0,path:"/about",component:B}),Object(a.jsx)(c.a,{exact:!0,path:"/submit",component:z}),Object(a.jsx)(c.a,{exact:!0,path:j.taskUrlTemplate,component:T}),Object(a.jsx)(c.a,{exact:!0,path:j.datasetUrlTemplate,component:F}),Object(a.jsx)(c.a,{exact:!0,path:"/datasets",component:W}),Object(a.jsx)(c.a,{exact:!0,path:"/terms-and-conditions",component:q}),Object(a.jsx)(c.a,{exact:!0,path:"/privacy-statement",component:G}),Object(a.jsx)(c.a,{path:"/",component:v})]})},H=n(45),J=n(22),X=n(92),K=(n(227),n(228),function(){return Object(a.jsxs)(H.a,{collapseOnSelect:!0,expand:"lg",children:[Object(a.jsx)("div",{className:"logo-wrapper",children:Object(a.jsxs)(H.a.Brand,{href:"/ro_benchmark_leaderboard",children:[Object(a.jsx)(O,{}),Object(a.jsxs)("div",{className:"logo-text",children:[" ","LiRo ",Object(a.jsx)("br",{})," BENCHMARK"," "]})]})}),Object(a.jsx)(H.a.Toggle,{"aria-controls":"menu-responsive"}),Object(a.jsx)(H.a.Collapse,{id:"menu-responsive",className:"justify-content-end",children:Object(a.jsxs)(J.a,{children:[Object(a.jsx)(J.a.Link,{href:"/ro_benchmark_leaderboard",children:"Tasks"}),Object(a.jsx)(J.a.Link,{href:j.datasetsPageUrl,children:"Datasets"}),Object(a.jsx)(J.a.Link,{href:j.submitPageUrl,children:"Submit"}),Object(a.jsx)(J.a.Link,{href:j.aboutPageUrl,children:"About"}),Object(a.jsxs)(X.a,{title:"Legal",id:"nav-dropdown-legal",children:[Object(a.jsx)(J.a.Link,{href:j.termsAndConditionsPageUrl,children:"Terms & Conditions"}),Object(a.jsx)(J.a.Link,{href:j.privacyStatementPageUrl,children:"Privacy statement"})]}),Object(a.jsxs)(J.a.Link,{className:"code-btn",href:"https://github.com/eemlcommunity/ro_benchmark_leaderboard",target:"_blank",rel:"noopener noreferrer",id:"code-btn",children:[Object(a.jsx)(w,{}),Object(a.jsx)("span",{children:"GitHub"})]})]})})]})}),Q=n(31),V=function(e){Object(m.a)(n,e);var t=Object(g.a)(n);function n(e){var a;return Object(u.a)(this,n),(a=t.call(this,e)).urlBuilder=new j,a.urlMap={"/about":"About","/submit":"Submit your model","/terms-and-conditions":"Terms and Conditions","/privacy-statement":"Privacy statement"},a}return Object(p.a)(n,[{key:"getTaskName",value:function(e){if(this.urlBuilder.isTaskUrl(e)){var t=this.urlBuilder.getTaskId(e);return k.tasks.find((function(e){return e.id===t})).task_name}if(this.urlBuilder.isDatasetUrl(e)){var n=this.urlBuilder.getDatasetId(e);return E.datasets.find((function(e){return e.id===n})).task}return null}},{key:"getTaskUrl",value:function(e){if(this.urlBuilder.isDatasetUrl(e)){var t=this.urlBuilder.getDatasetId(e),n=E.datasets.find((function(e){return e.id===t})),a=k.tasks.find((function(e){return e.task_name===n.task}));return this.urlBuilder.buildTaskUrl(a)}return null}},{key:"getDatasetName",value:function(e){if(this.urlBuilder.isDatasetUrl(e)){var t=this.urlBuilder.getDatasetId(e),n=E.datasets.find((function(e){return e.id===t}));return n.dataset_name.replace(" - ".concat(n.task),"").trim()}return null}},{key:"isOtherUrl",value:function(e){var t=this.urlBuilder.isHomeUrl(e),n=this.urlBuilder.isTaskUrl(e),a=this.urlBuilder.isDatasetUrl(e);return!(t||n||a)}},{key:"render",value:function(){var e=window.location.pathname;return this.urlBuilder.isHomeUrl(e)?null:Object(a.jsx)(a.Fragment,{children:Object(a.jsxs)(Q.a,{children:[Object(a.jsx)(Q.a.Item,{href:j.basePath,children:"Home"}),this.urlBuilder.isTaskUrl(e)&&Object(a.jsx)(Q.a.Item,{active:!0,children:this.getTaskName(e)}),this.urlBuilder.isDatasetUrl(e)&&Object(a.jsxs)(a.Fragment,{children:[Object(a.jsx)(Q.a.Item,{href:this.getTaskUrl(e),children:this.getTaskName(e)}),Object(a.jsx)(Q.a.Item,{active:!0,children:this.getDatasetName(e)})]}),this.isOtherUrl(e)&&Object(a.jsx)(Q.a.Item,{active:!0,children:this.urlMap[this.urlBuilder.getCanonicalUrl(e)]})]})})}}]),n}(s.a.Component),Z=(n(232),function(e){Object(m.a)(n,e);var t=Object(g.a)(n);function n(e){var a;return Object(u.a)(this,n),(a=t.call(this,e)).urlBuilder=new j,a}return Object(p.a)(n,[{key:"render",value:function(){return Object(a.jsx)("footer",{className:"footer",children:Object(a.jsxs)("div",{className:"footer-content",children:[Object(a.jsxs)("div",{className:"footer-message",children:["Contact us at ",Object(a.jsx)("a",{href:"mailto:contact@eeml.eu",children:"contact@eeml.eu"}),"."]}),Object(a.jsxs)("div",{className:"footer-message",children:["Follow us on ",Object(a.jsx)("a",{href:"https://twitter.com/EEMLcommunity",children:"Twitter"}),"."]}),Object(a.jsx)("div",{className:"footer-message",children:"Logo design by Cristina One\u021b."})]})})}}]),n}(s.a.Component)),$=(n(233),function(e){var t=e.location;return Object(a.jsxs)("div",{children:[Object(a.jsx)(K,{}),Object(a.jsx)(V,{}),Object(a.jsx)("div",{className:"main-content",children:Object(a.jsx)(Y,{location:t})}),Object(a.jsx)(Z,{})]})});h.a.load({google:{families:["Roboto:300,400,700","sans-serif"]}}),o.a.render(Object(a.jsx)(l.a,{basename:"/ro_benchmark_leaderboard",children:Object(a.jsx)(c.a,{path:"/",component:$})}),document.getElementById("root"))},26:function(e){e.exports=JSON.parse('{"tasks":[{"area":"NLP","id":"text-classification","task_name":"Text Classification","task_description":"Text classification is the task of assigning a sentence or document an appropriate category. The categories depend on the chosen dataset and can range from topics.","datasets":[{"dataset_id":"moroco","dataset_name":"MOROCO","metric":"F1","model_name":"","paper_title":"","paper_link":"","source_link":""}]},{"area":"NLP","id":"ner","task_name":"NER","task_description":"Named entity recognition (NER) is the task of tagging entities in text with their corresponding type. Approaches typically use BIO notation, which differentiates the beginning (B) and the inside (I) of entities. O is used for non-entity tokens.","datasets":[{"dataset_id":"ronec-romanian-named-entity-corpus-v1-0","dataset_name":"RONEC - Romanian Named Entity Corpus v1.0","metric":"Exact Match F1","model_name":"","paper_title":"","paper_link":"","source_link":""}]},{"area":"NLP","id":"machine-translation","task_name":"Machine Translation","task_description":"Machine translation is the task of translating a sentence in a source language to a different target language","datasets":[{"dataset_id":"ro-sts-parallel","dataset_name":"RO-STS-parallel","metric":"BLEU","model_name":"","paper_title":"","paper_link":"","source_link":""},{"dataset_id":"wmt16-en-ro","dataset_name":"WMT16-EN-RO","metric":"BLEU","model_name":"","paper_title":"","paper_link":"","source_link":""}]},{"area":"NLP","id":"tokenization","task_name":"Tokenization","task_description":"Tokenization is the process of breaking a stream of text up into words, phrases, symbols, or other meaningful elements called tokens. The list of tokens becomes input for further processing such as parsing or text mining.","datasets":[{"dataset_id":"ud-romanian-rrt-treebank-v2-5-tokenization","dataset_name":"UD Romanian RRT Treebank v2.5 - Tokenization","metric":"Tokens F1","model_name":"NLP-Cube v1.1 [end-to-end]","paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube"}]},{"area":"NLP","id":"sentence-segmentation","task_name":"Sentence Segmentation","task_description":"Sentence segmentation is the task of splitting a sentence into its component phrases.","datasets":[{"dataset_id":"ud-romanian-rrt-treebank-v2-5-sentence-segmentation","dataset_name":"UD Romanian RRT Treebank v2.5 - Sentence Segmentation","metric":"Sentences F1","model_name":"NLP-Cube v1.1 [end-to-end]","paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube"}]},{"area":"NLP","id":"lemmatization","task_name":"Lemmatization","task_description":"Lemmatization is the process of identifying the lemma of a given word or sequence of words.","datasets":[{"dataset_id":"ud-romanian-rrt-treebank-v2-5-lemmatization","dataset_name":"UD Romanian RRT Treebank v2.5 - Lemmatization","metric":"Lemma F1","model_name":"NLP-Cube v1.1 [end-to-end]","paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube"}]},{"area":"NLP","id":"pos-tagging","task_name":"POS Tagging","task_description":"Part-of-speech tagging (POS tagging) is the task of tagging a word in a text with its part of speech. A part of speech is a category of words with similar grammatical properties.","datasets":[{"dataset_id":"ud-romanian-rrt-treebank-v2-5-part-of-speech-tagging","dataset_name":"UD Romanian RRT Treebank v2.5 - Part of Speech Tagging","metric":"UPOS F1","model_name":"NLP-Cube v1.1 [end-to-end]","paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube"}]},{"area":"NLP","id":"dependency-parsing","task_name":"Dependency Parsing","task_description":"Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between \\"head\\" words and words, which modify those heads.","datasets":[{"dataset_id":"ud-romanian-rrt-treebank-v2-5-dependency-parsing","dataset_name":"UD Romanian RRT Treebank v2.5 - Dependency Parsing","metric":"UAS F1","model_name":"NLP-Cube v1.1 [end-to-end]","paper_title":"NLP-Cube: End-to-End Raw Text Processing With Neural Networks","paper_link":"http://www.aclweb.org/anthology/K18-2017","source_link":"https://github.com/adobe/NLP-Cube"}]},{"area":"NLP","id":"language-modeling","task_name":"Language Modeling","task_description":"Language modeling is the task of predicting the next word or character in a document.","datasets":[]},{"area":"NLP","id":"question-answering","task_name":"Question Answering","task_description":"Question Answering (QA) systems enable users to retrieve exact answers for questions posed in natural language. This task covers all QA systems for Romanian, with datasets that contain in-domain training data as well as zero-shot cross-linugal datasets.","datasets":[{"dataset_id":"xquad-ro","dataset_name":"XQuAD-ro","metric":"F1","model_name":"mBERT","paper_title":"(results available online only, Romanian evaluated by DeepMind XQuAD dataset creators)","paper_link":"https://github.com/deepmind/xquad","source_link":""}]},{"area":"NLP","id":"sentiment-analysis","task_name":"Sentiment Analysis","task_description":"A sentiment analysis system combines natural language processing (NLP) and machine learning techniques to assign weighted sentiment scores to the entities, topics, themes and/or categories within a phrase, sentence or document.","datasets":[{"dataset_id":"laroseda","dataset_name":"LaRoSeDa","metric":"F1","model_name":"","paper_title":"","paper_link":"","source_link":""}]},{"area":"NLP","id":"semantic-textual-similarity","task_name":"Semantic Textual Similarity","task_description":"Semantic textual similarity deals with determining how similar two sentences or documents are. Similarity can be measured as an interval, like 1 (no relation between two texts) to 5 (the two texts fully convey the same meaning). Standard dataset measures include Pearson and Spearman correlations.","datasets":[{"dataset_id":"ro-sts","dataset_name":"RO-STS","metric":"Pearson Correlation","model_name":"RO-STS Baseline RNN","paper_title":"","paper_link":"","source_link":"https://github.com/dumitrescustefan/RO-STS"}]}]}')},90:function(e){e.exports=JSON.parse('{"areas":[{"name":"NLP","tasks":[{"id":"text-classification","name":"Text Classification","summary":{"dataset_count":1,"submission_count":0}},{"id":"ner","name":"NER","summary":{"dataset_count":1,"submission_count":0}},{"id":"machine-translation","name":"Machine Translation","summary":{"dataset_count":2,"submission_count":0}},{"id":"tokenization","name":"Tokenization","summary":{"dataset_count":1,"submission_count":2}},{"id":"sentence-segmentation","name":"Sentence Segmentation","summary":{"dataset_count":1,"submission_count":2}},{"id":"lemmatization","name":"Lemmatization","summary":{"dataset_count":1,"submission_count":2}},{"id":"pos-tagging","name":"POS Tagging","summary":{"dataset_count":1,"submission_count":3}},{"id":"dependency-parsing","name":"Dependency Parsing","summary":{"dataset_count":1,"submission_count":2}},{"id":"language-modeling","name":"Language Modeling","summary":{"dataset_count":0,"submission_count":0}},{"id":"question-answering","name":"Question Answering","summary":{"dataset_count":1,"submission_count":2}},{"id":"sentiment-analysis","name":"Sentiment Analysis","summary":{"dataset_count":1,"submission_count":0}},{"id":"semantic-textual-similarity","name":"Semantic Textual Similarity","summary":{"dataset_count":1,"submission_count":3}}]}]}')}},[[234,1,2]]]);
//# sourceMappingURL=main.f852836b.chunk.js.map